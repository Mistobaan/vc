{"id":"vc-1","title":"Activity Feed and Event Streaming","description":"Implement comprehensive event journaling and real-time activity feed for observability. Without this, debugging AI agents is nearly impossible. Must-have before dogfooding.","design":"Event-based system that logs all executor actions, AI assessments, issue state changes, and agent interactions. Provides 'vc executor tail' command for real-time monitoring.","acceptance_criteria":"- Event journal table in database\n- Activity feed CLI command working\n- Real-time tail functionality\n- Integration with issue processor\n- Events logged for: issue claims, AI assessments, executions, quality gates, issue closures","status":"open","priority":0,"issue_type":"epic","created_at":"2025-10-13T21:05:19.448795-07:00","updated_at":"2025-10-14T12:36:26.509898-07:00","dependencies":[{"issue_id":"vc-1","depends_on_id":"vc-9","type":"blocks","created_at":"2025-10-13T21:05:19.449797-07:00","created_by":"import"}]}
{"id":"vc-10","title":"Verify existing Beads fields and add discovered-from dependency type","description":"Quick verification that design, acceptance_criteria, and notes fields work correctly. Add the 'discovered-from' dependency type constant to support tracking work discovered during execution.","design":"1. Write test to verify design/acceptance_criteria/notes fields can be set and retrieved. 2. Add DepDiscoveredFrom constant to internal/types/types.go. 3. Update DependencyType.IsValid() to include new type. 4. Test creating dependencies with discovered-from type.","acceptance_criteria":"- Test confirms design, acceptance_criteria, notes fields work correctly\\n- DepDiscoveredFrom constant added to types\\n- IsValid() function updated\\n- Can create and query dependencies with type 'discovered-from'\\n- Documentation updated","status":"closed","priority":0,"issue_type":"task","created_at":"2025-10-13T21:21:48.323451-07:00","updated_at":"2025-10-14T12:36:26.511684-07:00","closed_at":"2025-10-13T23:14:01.180328-07:00"}
{"id":"vc-11","title":"Design and implement executor_instances table","description":"Create the executor_instances table to track which executor instances are running. This enables multi-executor coordination and stale instance cleanup.","design":"Schema: instance_id (TEXT PK), hostname (TEXT), pid (INTEGER), status (running/stopped), started_at (DATETIME), last_heartbeat (DATETIME), version (TEXT), metadata (JSON). Add to Storage interface: RegisterInstance(), UpdateHeartbeat(), GetActiveInstances(), CleanupStaleInstances(). Implement in SQLite backend. Add indexes on status and last_heartbeat.","acceptance_criteria":"- executor_instances table created in schema.go\\n- Storage interface methods added\\n- SQLite implementation complete\\n- Registration and heartbeat functions work\\n- Stale instance cleanup logic implemented\\n- Schema documented with comments\\n- Basic unit tests pass","status":"closed","priority":0,"issue_type":"task","created_at":"2025-10-13T21:22:26.6102-07:00","updated_at":"2025-10-14T12:36:26.512025-07:00","closed_at":"2025-10-13T23:20:23.133979-07:00","dependencies":[{"issue_id":"vc-11","depends_on_id":"vc-10","type":"blocks","created_at":"2025-10-13T21:22:53.549651-07:00","created_by":"stevey"}]}
{"id":"vc-12","title":"Design and implement issue_execution_state table","description":"Create the issue_execution_state table for checkpoint/resume support. This enables executors to save progress and resume after interruption.","design":"Schema: issue_id (TEXT FK), executor_instance_id (TEXT FK), state (claimed/assessing/executing/analyzing/gates/completed), checkpoint_data (JSON), started_at (DATETIME), updated_at (DATETIME). Add atomic ClaimIssue() that inserts execution_state row and updates issue status. Add SaveCheckpoint(), GetCheckpoint(), ResumeFromCheckpoint(). State machine: claimed → assessing → executing → analyzing → gates → completed.","acceptance_criteria":"- issue_execution_state table created in schema.go\\n- Atomic ClaimIssue() prevents double-claiming\\n- SaveCheckpoint()/GetCheckpoint() work with JSON data\\n- State transitions enforced\\n- Foreign keys to issues and executor_instances\\n- Schema documented\\n- Unit tests for claim and checkpoint operations","status":"closed","priority":0,"issue_type":"task","created_at":"2025-10-13T21:22:27.670681-07:00","updated_at":"2025-10-14T12:36:26.512225-07:00","closed_at":"2025-10-13T23:38:20.208109-07:00","dependencies":[{"issue_id":"vc-12","depends_on_id":"vc-11","type":"blocks","created_at":"2025-10-13T21:22:53.554608-07:00","created_by":"stevey"}]}
{"id":"vc-13","title":"Implement PostgreSQL backend","description":"Implement PostgreSQL storage backend. Port all schemas (issues, dependencies, executor tables) to PostgreSQL DDL and implement the Storage interface for postgres.","design":"Create internal/storage/postgres/ package mirroring sqlite structure. Port schema DDL to PostgreSQL (use JSONB for metadata/checkpoints). Implement all Storage interface methods. Add connection pooling with pgx. Create factory function in storage package to return correct backend based on config. Test switching between backends.","acceptance_criteria":"- postgres package created with full Storage implementation\\n- All schemas ported to PostgreSQL DDL\\n- Connection pooling configured\\n- Backend factory function works\\n- Can switch between SQLite and PostgreSQL via config\\n- All basic operations work on PostgreSQL\\n- Connection lifecycle handled correctly","status":"closed","priority":0,"issue_type":"task","created_at":"2025-10-13T21:22:29.436751-07:00","updated_at":"2025-10-14T13:01:05.011403-07:00","closed_at":"2025-10-14T13:01:05.011403-07:00","dependencies":[{"issue_id":"vc-13","depends_on_id":"vc-12","type":"blocks","created_at":"2025-10-13T21:22:53.559463-07:00","created_by":"stevey"},{"issue_id":"vc-13","depends_on_id":"vc-16","type":"parent-child","created_at":"2025-10-13T23:48:30.576326-07:00","created_by":"stevey"},{"issue_id":"vc-13","depends_on_id":"vc-17","type":"parent-child","created_at":"2025-10-13T23:48:30.581578-07:00","created_by":"stevey"},{"issue_id":"vc-13","depends_on_id":"vc-18","type":"parent-child","created_at":"2025-10-13T23:48:30.586692-07:00","created_by":"stevey"},{"issue_id":"vc-13","depends_on_id":"vc-19","type":"parent-child","created_at":"2025-10-13T23:48:30.591391-07:00","created_by":"stevey"},{"issue_id":"vc-13","depends_on_id":"vc-20","type":"parent-child","created_at":"2025-10-13T23:48:30.596101-07:00","created_by":"stevey"},{"issue_id":"vc-13","depends_on_id":"vc-21","type":"parent-child","created_at":"2025-10-13T23:48:30.600945-07:00","created_by":"stevey"}]}
{"id":"vc-14","title":"Create migration and initialization scripts","description":"Create scripts/functions to initialize fresh databases and handle schema migrations for both SQLite and PostgreSQL.","design":"Add InitDatabase() function that creates all tables with current schema. Create internal/storage/migrations package. Design simple migration system: version table, sequential numbered migrations, up/down support. Create scripts/init-db.sh for CLI usage. Document bootstrap process in CLAUDE.md. Consider using golang-migrate or similar for production migrations.","acceptance_criteria":"- InitDatabase() creates all tables for both backends\\n- Migration framework designed and documented\\n- scripts/init-db.sh can bootstrap fresh database\\n- Version tracking table exists\\n- At least one test migration created and works\\n- Bootstrap process documented\\n- Works for both SQLite and PostgreSQL","status":"closed","priority":0,"issue_type":"task","created_at":"2025-10-13T21:22:30.615509-07:00","updated_at":"2025-10-14T13:04:42.168525-07:00","closed_at":"2025-10-14T13:04:42.168525-07:00","dependencies":[{"issue_id":"vc-14","depends_on_id":"vc-13","type":"blocks","created_at":"2025-10-13T21:22:53.563882-07:00","created_by":"stevey"}]}
{"id":"vc-15","title":"Integration tests for executor functionality","description":"Write integration tests validating the full executor table functionality, including multi-executor scenarios, claim/checkpoint/resume flows, and both database backends.","design":"Create internal/storage/integration_test.go. Test scenarios: 1) Multiple executors claiming different issues (no conflicts), 2) Claim race condition handling, 3) Checkpoint save and restore, 4) Stale instance cleanup, 5) Resume after interruption, 6) All above on both SQLite and PostgreSQL. Use table-driven tests to run same scenarios on both backends.","acceptance_criteria":"- Integration test file created\\n- Multi-executor claim scenarios pass\\n- Race condition tests pass (no double-claiming)\\n- Checkpoint/resume cycle works\\n- Stale instance cleanup verified\\n- All tests pass on SQLite\\n- All tests pass on PostgreSQL\\n- Test coverage documented","notes":"Deferred: Integration tests should be written after executor implementation (vc-6) is complete. Current unit tests provide adequate coverage for database operations. Integration tests will validate the full executor workflow including race conditions, checkpoint/resume, and multi-executor coordination in a real execution context.","status":"open","priority":0,"issue_type":"task","created_at":"2025-10-13T21:22:31.886325-07:00","updated_at":"2025-10-14T13:10:13.238041-07:00","dependencies":[{"issue_id":"vc-15","depends_on_id":"vc-14","type":"blocks","created_at":"2025-10-13T21:22:53.568457-07:00","created_by":"stevey"},{"issue_id":"vc-15","depends_on_id":"vc-6","type":"blocks","created_at":"2025-10-14T13:10:14.294156-07:00","created_by":"stevey"}]}
{"id":"vc-16","title":"Create postgres.go with connection pooling and base structure","description":"Create internal/storage/postgres/postgres.go with PostgresStorage struct, connection pooling via pgx.Pool, New() constructor, and Close() method. Set up basic structure mirroring SQLite implementation.","design":"Use pgx/v5 connection pool. Connection string: postgres://user:pass@host:port/dbname. Configure pool size, timeouts. Initialize schema on New(). Implement proper connection lifecycle.","acceptance_criteria":"- PostgresStorage struct with pgx.Pool\\n- New() constructor with connection pooling\\n- Schema initialization on startup\\n- Close() method for cleanup\\n- Connection string parsing\\n- Pool configuration (max conns, timeouts)\\n- Error handling for connection failures","status":"closed","priority":0,"issue_type":"task","created_at":"2025-10-13T23:47:34.720193-07:00","updated_at":"2025-10-14T12:36:26.51295-07:00","closed_at":"2025-10-14T00:03:08.987536-07:00"}
{"id":"vc-17","title":"Implement PostgreSQL issue operations","description":"Implement issue CRUD operations in PostgreSQL: CreateIssue, GetIssue, UpdateIssue, CloseIssue, SearchIssues. Port from SQLite implementation, converting ? placeholders to $1, $2, etc.","design":"Port issue operations from internal/storage/sqlite/sqlite.go. Use numbered placeholders ($1, $2). Handle ID generation for new issues. Implement field validation. Use transactions where appropriate. Handle NULL values correctly for optional fields (assignee, estimated_minutes, closed_at).","acceptance_criteria":"- CreateIssue() works with ID generation\\n- GetIssue() retrieves issues correctly\\n- UpdateIssue() handles partial updates\\n- CloseIssue() sets status and closed_at\\n- SearchIssues() supports filtering and pagination\\n- Event logging integrated\\n- Validation enforced\\n- Transactions used appropriately","status":"closed","priority":0,"issue_type":"task","created_at":"2025-10-13T23:47:48.249848-07:00","updated_at":"2025-10-14T12:36:26.513295-07:00","closed_at":"2025-10-14T00:05:51.918897-07:00","dependencies":[{"issue_id":"vc-17","depends_on_id":"vc-16","type":"blocks","created_at":"2025-10-13T23:48:44.920406-07:00","created_by":"stevey"}]}
{"id":"vc-18","title":"Implement PostgreSQL dependency, label, and event operations","description":"Port dependencies.go, labels.go, and events.go from SQLite to PostgreSQL. Implement AddDependency, RemoveDependency, GetDependencies, GetDependents, GetDependencyTree, DetectCycles for dependencies. AddLabel, RemoveLabel, GetLabels, GetIssuesByLabel for labels. AddComment, GetEvents for events.","design":"Port from SQLite files. Convert ? to $N. Handle foreign key constraints. Implement cycle detection algorithm. Use recursive CTEs for dependency tree queries in PostgreSQL.","acceptance_criteria":"- All dependency operations work\\n- All label operations work\\n- All event operations work\\n- Cycle detection functional\\n- Dependency tree query efficient\\n- Foreign keys enforced\\n- Event logging works","status":"closed","priority":0,"issue_type":"task","created_at":"2025-10-13T23:48:04.079317-07:00","updated_at":"2025-10-14T12:36:26.513532-07:00","closed_at":"2025-10-14T00:22:21.848492-07:00","dependencies":[{"issue_id":"vc-18","depends_on_id":"vc-17","type":"blocks","created_at":"2025-10-13T23:48:44.925689-07:00","created_by":"stevey"}]}
{"id":"vc-19","title":"Implement PostgreSQL executor instance operations","description":"Port executor_instances.go from SQLite to PostgreSQL. Implement RegisterInstance, UpdateHeartbeat, GetActiveInstances, CleanupStaleInstances. Handle JSONB metadata field.","design":"Port from sqlite/executor_instances.go. Use JSONB for metadata. Implement upsert pattern for RegisterInstance. Use timestamptz comparisons for stale detection. Handle connection pool correctly.","acceptance_criteria":"- RegisterInstance works with upsert\\n- UpdateHeartbeat updates timestamp\\n- GetActiveInstances filters by status\\n- CleanupStaleInstances handles threshold\\n- JSONB metadata handled correctly\\n- All operations tested","status":"closed","priority":0,"issue_type":"task","created_at":"2025-10-13T23:48:04.085658-07:00","updated_at":"2025-10-14T12:36:26.513726-07:00","closed_at":"2025-10-14T03:10:24.249484-07:00","dependencies":[{"issue_id":"vc-19","depends_on_id":"vc-16","type":"blocks","created_at":"2025-10-13T23:48:44.931383-07:00","created_by":"stevey"}]}
{"id":"vc-2","title":"Recursive Refinement and Follow-On Missions","description":"The core of 'Engineer-in-a-Box'. AI analyzes execution results and automatically creates follow-on issues for discovered work, punted items, and quality problems. This is what makes vc self-improving instead of just a task executor.","design":"After each issue execution, AI analyzes the result and extracts: 1) Punted work (deferred items), 2) Discovered bugs/issues, 3) Quality problems. Automatically creates child issues with 'discovered-from' dependencies. Executor processes these recursively until all work is complete.","acceptance_criteria":"- analyzeExecutionResult AI activity implemented\n- Automatic issue creation from AI analysis\n- discovered-from dependency type support\n- Punted items labeled and tracked\n- Quality issues create blocking dependencies\n- Recursive processing until convergence\n- Integration with quality gates","status":"open","priority":0,"issue_type":"epic","created_at":"2025-10-13T21:05:19.449075-07:00","updated_at":"2025-10-14T12:36:26.513925-07:00","dependencies":[{"issue_id":"vc-2","depends_on_id":"vc-1","type":"blocks","created_at":"2025-10-13T21:05:19.449939-07:00","created_by":"import"}]}
{"id":"vc-20","title":"Implement PostgreSQL execution state and ready work operations","description":"Port execution_state.go and ready.go from SQLite to PostgreSQL. Implement ClaimIssue, GetExecutionState, UpdateExecutionState, SaveCheckpoint, GetCheckpoint, ReleaseIssue for execution state. Implement GetReadyWork, GetBlockedIssues, GetStatistics for ready work queries. Use JSONB for checkpoint data.","design":"Port from SQLite. Use JSONB for checkpoint_data. Implement atomic ClaimIssue with proper PostgreSQL locking. Use views for ready_issues and blocked_issues queries. Implement statistics aggregation efficiently.","acceptance_criteria":"- ClaimIssue atomic and prevents double-claiming\\n- All execution state operations work\\n- GetReadyWork returns correct issues\\n- GetBlockedIssues identifies blocked work\\n- GetStatistics provides accurate counts\\n- JSONB checkpoint data handled\\n- State machine enforced","status":"closed","priority":0,"issue_type":"task","created_at":"2025-10-13T23:48:21.302415-07:00","updated_at":"2025-10-14T12:36:26.514096-07:00","closed_at":"2025-10-14T03:32:23.904021-07:00","dependencies":[{"issue_id":"vc-20","depends_on_id":"vc-17","type":"blocks","created_at":"2025-10-13T23:48:44.937538-07:00","created_by":"stevey"},{"issue_id":"vc-20","depends_on_id":"vc-19","type":"blocks","created_at":"2025-10-13T23:48:44.942434-07:00","created_by":"stevey"}]}
{"id":"vc-21","title":"Create storage factory function for backend selection","description":"Add factory function in internal/storage/storage.go to create correct backend (SQLite or PostgreSQL) based on Config. Enable switching between backends via configuration.","design":"Add NewStorage(config Config) (Storage, error) function. Check config.Backend field. Return sqlite.New() or postgres.New() based on backend. Handle connection string building for PostgreSQL. Validate config before creating backend.","acceptance_criteria":"- NewStorage() factory function works\\n- Selects SQLite when config.Backend='sqlite'\\n- Selects PostgreSQL when config.Backend='postgres'\\n- Config validation implemented\\n- Connection string handling correct\\n- Error messages clear\\n- Can switch backends easily","status":"closed","priority":0,"issue_type":"task","created_at":"2025-10-13T23:48:21.307824-07:00","updated_at":"2025-10-14T12:36:26.51428-07:00","closed_at":"2025-10-14T01:10:59.496449-07:00","dependencies":[{"issue_id":"vc-21","depends_on_id":"vc-16","type":"blocks","created_at":"2025-10-13T23:48:44.947254-07:00","created_by":"stevey"}]}
{"id":"vc-22","title":"Fix PostgreSQL ID generation race condition","description":"The getNextID() function in postgres.go has a race condition in multi-executor scenarios. Two executors can both read MAX(id) and get the same nextID, leading to UNIQUE constraint violations.","design":"Options: 1) Use PostgreSQL SEQUENCE for ID generation (most robust), 2) Use atomic database-side ID allocation (SELECT ... FOR UPDATE), 3) Document that each executor should have its own ID range. Recommended: PostgreSQL sequence with 'vc-' prefix using a custom function.","acceptance_criteria":"- ID generation is thread-safe across multiple executor instances\\n- No UNIQUE constraint violations possible\\n- Tests verify concurrent ID generation\\n- Performance acceptable (\u003c 5ms per ID)","notes":"Fixed race condition by replacing in-memory counter with PostgreSQL sequence. Added next_issue_id() function that uses issue_id_seq. Removed getNextID() and mutex. Added comprehensive tests for concurrent ID generation and performance.","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-10-14T00:15:22.574086-07:00","updated_at":"2025-10-14T12:36:26.51447-07:00","closed_at":"2025-10-14T11:09:57.203873-07:00"}
{"id":"vc-23","title":"Fix error handling in getNextID function","description":"The getNextID() function in postgres.go silently ignores errors. On line 134, 'if err \\!= nil \u0026\u0026 err \\!= pgx.ErrNoRows' returns 1 instead of propagating the error. Network failures, permission errors, etc. would be masked.","design":"Change logic to: 1) Check if err == pgx.ErrNoRows, return 1, 2) If any other error, return error with context, 3) Add test for error propagation.","acceptance_criteria":"- Network errors properly propagated\\n- Permission errors properly propagated\\n- Only pgx.ErrNoRows returns default ID\\n- Error messages include context\\n- Test coverage for error cases","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-10-14T00:15:31.139269-07:00","updated_at":"2025-10-14T12:36:26.514658-07:00","closed_at":"2025-10-14T11:12:23.843624-07:00"}
{"id":"vc-24","title":"Add context deadline checks to long-running PostgreSQL queries","description":"Long-running queries like DetectCycles and GetDependencyTree don't check ctx.Done(). If a client disconnects or times out, these queries continue running as zombies, wasting database resources.","design":"Add context deadline checks in loops that process rows. Use ctx.Err() to detect cancellation. For recursive CTEs, consider setting statement_timeout in PostgreSQL. Add integration tests with cancelled contexts.","acceptance_criteria":"- DetectCycles respects context cancellation\\n- GetDependencyTree respects context cancellation\\n- Zombie queries cleaned up on client disconnect\\n- Tests verify cancellation behavior\\n- No resource leaks on timeout","status":"open","priority":2,"issue_type":"task","created_at":"2025-10-14T00:15:40.585971-07:00","updated_at":"2025-10-14T12:36:26.514838-07:00"}
{"id":"vc-25","title":"Add helper function for scanning issues in PostgreSQL backend","description":"The postgres.go file has duplicated issue scanning logic in SearchIssues, GetDependencies, GetDependents, and other methods. SQLite has a scanIssues() helper that should be replicated for PostgreSQL.","design":"Create scanIssues(rows pgx.Rows) ([]*types.Issue, error) helper function. Handle NULL values for closedAt, estimatedMinutes, assignee consistently. Use in all methods that return []*types.Issue.","acceptance_criteria":"- scanIssues helper function created\\n- All issue-returning methods use helper\\n- NULL handling consistent across methods\\n- Code duplication eliminated\\n- No behavior changes (tests pass)","status":"open","priority":3,"issue_type":"task","created_at":"2025-10-14T00:15:51.288622-07:00","updated_at":"2025-10-14T12:36:26.51515-07:00"}
{"id":"vc-26","title":"Add connection pool metrics and observability to PostgreSQL backend","description":"The PostgreSQL connection pool (pgxpool) provides metrics like active connections, idle connections, wait time, etc. These should be exposed for monitoring and debugging production issues.","design":"Use pgxpool.Stat() to expose metrics. Options: 1) Add GetPoolStats() method to Storage interface, 2) Export metrics to Prometheus, 3) Log periodic stats. Consider adding pool exhaustion warnings.","acceptance_criteria":"- Pool stats exposed via API\\n- Active/idle connection counts available\\n- Wait time/duration tracked\\n- Pool exhaustion warnings logged\\n- Metrics helpful for debugging production issues","status":"open","priority":3,"issue_type":"task","created_at":"2025-10-14T00:16:00.172988-07:00","updated_at":"2025-10-14T12:36:26.515321-07:00"}
{"id":"vc-27","title":"Fix AddLabel/RemoveLabel to check RowsAffected before recording events","description":"AddLabel and RemoveLabel in PostgreSQL backend record events even when no changes occur. AddLabel uses ON CONFLICT DO NOTHING but still records event if label already exists. RemoveLabel records event even if label doesn't exist. This creates misleading audit trail.","design":"Check CommandTag.RowsAffected() after INSERT/DELETE operations. Only record event if rows were actually modified. For AddLabel: result.RowsAffected() \u003e 0. For RemoveLabel: result.RowsAffected() \u003e 0.","acceptance_criteria":"AddLabel skips event when label already exists; RemoveLabel skips event when label doesn't exist; audit trail only shows actual changes","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-10-14T00:36:26.579297-07:00","updated_at":"2025-10-14T12:36:26.515501-07:00","closed_at":"2025-10-14T02:28:38.026064-07:00"}
{"id":"vc-28","title":"Fix DetectCycles N+1 query problem with bulk issue fetch","description":"DetectCycles in PostgreSQL backend has N+1 query problem at postgres.go:792-800. For each issue ID in a cycle path, it calls GetIssue() separately. A cycle with 10 issues makes 10 database round trips. This is inefficient and doesn't scale.","design":"After parsing all cycle paths and collecting unique issue IDs, make single bulk query: SELECT * FROM issues WHERE id IN ($1, $2, ...). Build map[issueID]*Issue for lookup. Then assemble cycles from map. Reduces N queries to 1.","acceptance_criteria":"DetectCycles makes single bulk query for all issues in all cycles; performance scales with unique issues not cycle count","status":"closed","priority":0,"issue_type":"bug","created_at":"2025-10-14T00:36:43.202121-07:00","updated_at":"2025-10-14T12:36:26.515794-07:00","closed_at":"2025-10-14T00:50:03.660637-07:00"}
{"id":"vc-29","title":"Fix AddDependency race condition by moving validation into transaction","description":"AddDependency validates issue existence at postgres.go:499-513 BEFORE starting transaction at line 523. Race condition: issues could be deleted between validation and insertion, causing foreign key violations or inconsistent state. Also makes 2 extra round trips.","design":"Move GetIssue validation calls inside transaction after Begin(). Or better: remove explicit validation and rely on foreign key constraints - let database enforce referential integrity. Catch and translate FK violation errors to user-friendly messages.","acceptance_criteria":"AddDependency validation happens inside transaction; no race condition possible; foreign key violations handled gracefully","status":"closed","priority":0,"issue_type":"bug","created_at":"2025-10-14T00:36:59.992736-07:00","updated_at":"2025-10-14T12:36:26.516247-07:00","closed_at":"2025-10-14T00:46:08.300061-07:00"}
{"id":"vc-3","title":"Watchdog and Convergence Detection","description":"Prevents infinite loops, stuck issues, and low-confidence spirals. Monitors executor progress and escalates when tasks aren't making forward progress. Should-have for production reliability.","design":"Monitor executor iterations and detect: 1) Max iterations without issue completion, 2) Repeated low-confidence AI assessments, 3) No progress within time threshold, 4) Escalation count exceeding limit. When detected, escalate to human or abort gracefully.","acceptance_criteria":"- Watchdog monitor component\n- maxIterationsWithoutProgress tracking\n- maxLowConfidenceAssessments tracking\n- minProgressCheckInterval enforcement\n- Escalation thresholds\n- Graceful abort on convergence failure\n- Logging and metrics integration","status":"open","priority":1,"issue_type":"epic","created_at":"2025-10-13T21:05:19.449174-07:00","updated_at":"2025-10-14T12:36:26.516428-07:00","dependencies":[{"issue_id":"vc-3","depends_on_id":"vc-2","type":"blocks","created_at":"2025-10-13T21:05:19.450051-07:00","created_by":"import"}]}
{"id":"vc-30","title":"Add limit validation to GetEvents in PostgreSQL backend","description":"GetEvents at postgres.go:942-945 accepts limit parameter but doesn't validate it. Negative or excessively large limits could cause issues. While integer formatting prevents SQL injection, unbounded queries are a DoS risk.","design":"Add validation: if limit \u003c 0 return error. If limit \u003e 10000 cap at 10000 or return error. Document maximum in function comment.","acceptance_criteria":"GetEvents rejects negative limits; enforces reasonable maximum; documented behavior","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-10-14T00:37:14.878662-07:00","updated_at":"2025-10-14T12:36:26.516692-07:00","closed_at":"2025-10-14T02:28:23.060423-07:00"}
{"id":"vc-31","title":"Fix GetDependencyTree truncation flag logic","description":"GetDependencyTree at postgres.go:722 sets node.Truncated = node.Depth == maxDepth. This is off-by-one: should be \u003e= maxDepth. Nodes AT maxDepth are the last level returned, so they ARE truncated (their children aren't shown). Current code would only mark imaginary 'maxDepth+1' nodes.","design":"Change line 722 from == to \u003e=. Or better: set truncated=true for nodes whose depth == maxDepth-1 AND they have children in dependencies table. This shows truncation only when children actually exist.","acceptance_criteria":"Truncation flag correct when dependency tree reaches max depth","status":"closed","priority":2,"issue_type":"bug","created_at":"2025-10-14T00:37:31.476488-07:00","updated_at":"2025-10-14T12:51:27.951601-07:00","closed_at":"2025-10-14T12:51:27.951601-07:00"}
{"id":"vc-32","title":"Initialize GetLabels with empty slice instead of nil","description":"GetLabels at postgres.go:874 declares 'var labels []string' which creates nil slice. When no labels exist, returns nil instead of empty slice. Forces callers to check for nil vs empty. Go convention is to return empty slices, not nil.","design":"Change declaration to 'labels := []string{}' at postgres.go:874. Returns consistent empty slice when no labels found.","acceptance_criteria":"GetLabels returns empty slice [] instead of nil when issue has no labels","status":"closed","priority":2,"issue_type":"bug","created_at":"2025-10-14T00:37:47.544436-07:00","updated_at":"2025-10-14T12:51:02.104427-07:00","closed_at":"2025-10-14T12:51:02.104427-07:00"}
{"id":"vc-33","title":"Add rows.Err() checks after iteration in PostgreSQL queries","description":"Multiple query functions in PostgreSQL backend iterate rows but don't check rows.Err() afterward. GetLabels at postgres.go:881 is one example. If iteration stops due to error, we silently return partial results. Should check rows.Err() after loop completes.","design":"After for rows.Next() loops, add: if err := rows.Err(); err \\!= nil { return nil, fmt.Errorf(...) }. Apply to: GetLabels, scanIssues helper, and any other row iteration.","acceptance_criteria":"All row iterations check rows.Err(); partial results never returned silently on error","status":"closed","priority":2,"issue_type":"bug","created_at":"2025-10-14T00:38:03.875936-07:00","updated_at":"2025-10-14T12:36:26.519163-07:00","closed_at":"2025-10-14T02:28:44.707577-07:00"}
{"id":"vc-34","title":"Standardize error wrapping in PostgreSQL backend","description":"Error handling inconsistent across PostgreSQL backend. Some places properly wrap errors with fmt.Errorf and %w, others return raw errors. Example: GetLabels postgres.go:878 returns unwrapped 'err' from Scan. Makes debugging harder - can't trace error origin.","design":"Audit all error returns in postgres.go. Ensure every error is wrapped with context using fmt.Errorf with %w verb. Pattern: return nil, fmt.Errorf('operation failed: %w', err).","acceptance_criteria":"All errors in postgres.go properly wrapped with context; error messages include operation that failed","status":"open","priority":3,"issue_type":"task","created_at":"2025-10-14T00:38:21.410672-07:00","updated_at":"2025-10-14T12:36:26.519379-07:00"}
{"id":"vc-35","title":"Use parameterized LIMIT in GetEvents PostgreSQL query","description":"GetEvents at postgres.go:944 builds LIMIT clause using fmt.Sprintf string concatenation instead of query parameters. While safe (limit is int), this is inconsistent with rest of codebase which uses parameterized queries. Better practice to use placeholders.","design":"Change implementation to use query parameter. If limit \u003e 0, append 'LIMIT $2' to query string and pass limit as second parameter to pool.Query(). Requires adjusting parameter index.","acceptance_criteria":"GetEvents uses parameterized LIMIT clause instead of string concatenation","status":"open","priority":3,"issue_type":"task","created_at":"2025-10-14T00:38:38.293188-07:00","updated_at":"2025-10-14T12:36:26.520552-07:00"}
{"id":"vc-36","title":"Use consistent timestamp source in AddComment","description":"AddComment at postgres.go:930-932 uses NOW() SQL function for updated_at timestamp. This is evaluated at query execution time, not transaction start. Other functions use time.Now() in Go code for consistency. Mixing sources could cause timestamp ordering issues.","design":"Change 'UPDATE issues SET updated_at = NOW()' to 'UPDATE issues SET updated_at = $N' and pass time.Now() as parameter. Captures timestamp at same moment as event creation. Consistent with rest of codebase.","acceptance_criteria":"AddComment uses Go time.Now() instead of SQL NOW(); timestamps consistent across transaction","status":"open","priority":3,"issue_type":"task","created_at":"2025-10-14T00:38:54.553625-07:00","updated_at":"2025-10-14T12:36:26.520748-07:00"}
{"id":"vc-37","title":"Use pgx error codes instead of string matching for FK violations in AddDependency","description":"The AddDependency function in postgres.go currently uses brittle string matching to detect foreign key violations (lines 519-527). It uses strings.Contains() to check error messages, which can break if PostgreSQL changes error message format across versions or locales.\n\nCurrent implementation:\nif strings.Contains(err.Error(), \"foreign key constraint\") || strings.Contains(err.Error(), \"violates foreign key\") {\n    if strings.Contains(err.Error(), \"issue_id\") {\n        return fmt.Errorf(\"issue %s not found\", dep.IssueID)\n    }\n    if strings.Contains(err.Error(), \"depends_on_id\") {\n        return fmt.Errorf(\"dependency target %s not found\", dep.DependsOnID)\n    }\n    return fmt.Errorf(\"one or both issues not found\")\n}\n\nThis approach is fragile and not recommended for production code.","design":"Use pgx's error type system to properly detect and handle foreign key violations:\n\n1. Import github.com/jackc/pgx/v5/pgconn\n2. Use errors.As() to check if error is *pgconn.PgError\n3. Check pgErr.Code == \"23503\" (PostgreSQL FK violation error code)\n4. Use pgErr.ConstraintName to determine which FK was violated\n5. Return appropriate error messages based on constraint name\n\nExample:\nvar pgErr *pgconn.PgError\nif errors.As(err, \u0026pgErr) \u0026\u0026 pgErr.Code == \"23503\" {\n    // FK violation - check which constraint\n    if strings.Contains(pgErr.ConstraintName, \"issue_id\") {\n        return fmt.Errorf(\"issue %s not found\", dep.IssueID)\n    }\n    if strings.Contains(pgErr.ConstraintName, \"depends_on\") {\n        return fmt.Errorf(\"dependency target %s not found\", dep.DependsOnID)\n    }\n    return fmt.Errorf(\"one or both issues not found\")\n}\n\nThis uses PostgreSQL's standard error codes which are stable across versions.","acceptance_criteria":"- Import pgconn package\n- Replace string matching with pgErr.Code == \"23503\" check\n- Use pgErr.ConstraintName instead of matching error message text\n- Code compiles successfully\n- Error handling properly identifies which issue doesn't exist","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-10-14T00:55:22.478055-07:00","updated_at":"2025-10-14T12:36:26.52094-07:00","closed_at":"2025-10-14T01:02:46.978803-07:00"}
{"id":"vc-38","title":"Add empty ID validation in AddDependency","description":"The AddDependency function in postgres.go does not validate that dep.IssueID and dep.DependsOnID are non-empty before attempting database operations. While the foreign key constraint will catch missing issues, empty strings should be rejected early with a clear error message.\n\nCurrent code only checks for self-dependency:\nif dep.IssueID == dep.DependsOnID {\n    return fmt.Errorf(\"issue cannot depend on itself\")\n}\n\nBut does not check for empty strings, which would fail later with a less clear FK violation error.","design":"Add validation at the start of AddDependency (after self-dependency check):\n\nif dep.IssueID == \"\" || dep.DependsOnID == \"\" {\n    return fmt.Errorf(\"issue IDs cannot be empty\")\n}\n\nThis provides early validation with a clear error message before any database operations are attempted.","acceptance_criteria":"- Add empty string validation for both IssueID and DependsOnID\n- Return clear error message if either is empty\n- Validation occurs before any database operations\n- Code compiles successfully","status":"closed","priority":2,"issue_type":"bug","created_at":"2025-10-14T00:59:01.996936-07:00","updated_at":"2025-10-14T12:36:26.521133-07:00","closed_at":"2025-10-14T02:28:30.441616-07:00"}
{"id":"vc-39","title":"Add parameter limit protection in DetectCycles bulk query","description":"The DetectCycles function in postgres.go uses a bulk WHERE IN query to fetch all issues involved in cycles (lines 846-863). While this is a huge performance improvement over N+1 queries, it could hit PostgreSQL's parameter limit in pathological cases.\n\nPostgreSQL has a limit of 65535 parameters per query. If there are extremely large cycles or many cycles involving thousands of unique issues, the bulk query could fail.\n\nCurrent code:\nparams := make([]interface{}, len(issueIDList))\nplaceholders := make([]string, len(issueIDList))\nfor i, id := range issueIDList {\n    params[i] = id\n    placeholders[i] = fmt.Sprintf(\"$%d\", i+1)\n}\n\nbulkQuery := fmt.Sprintf(...)\nissueRows, err := s.pool.Query(ctx, bulkQuery, params...)\n\nThis could theoretically exceed parameter limits in extreme cases.","design":"Add batching logic to handle large numbers of issue IDs:\n\n1. Define a reasonable batch size (e.g., 1000 issues per query)\n2. If len(issueIDList) \u003c= batchSize, use current single-query approach\n3. If len(issueIDList) \u003e batchSize, split into batches:\n   - Process batches of up to 1000 IDs each\n   - Merge results into the issueMap\n4. Continue with existing cycle assembly logic\n\nExample:\nconst maxBatchSize = 1000\nissueMap := make(map[string]*types.Issue)\n\nfor i := 0; i \u003c len(issueIDList); i += maxBatchSize {\n    end := i + maxBatchSize\n    if end \u003e len(issueIDList) {\n        end = len(issueIDList)\n    }\n    batch := issueIDList[i:end]\n    \n    // Build and execute query for this batch\n    // Merge results into issueMap\n}\n\nThis ensures we never exceed PostgreSQL's parameter limits.","acceptance_criteria":"- Add batch size constant (1000 issues)\n- Implement batching logic when issue count exceeds limit\n- Single query optimization still used for small result sets\n- All issues fetched and merged correctly\n- Code compiles successfully","status":"closed","priority":2,"issue_type":"bug","created_at":"2025-10-14T00:59:15.75732-07:00","updated_at":"2025-10-14T12:36:26.521858-07:00","closed_at":"2025-10-14T02:28:51.518512-07:00"}
{"id":"vc-4","title":"Git Operations Integration","description":"Complete the loop from code changes to mergeable PR. Enables branch creation, commits with proper messages, and PR preparation. Should-have for true 'Engineer-in-a-Box' functionality.","design":"After quality gates pass, automatically: 1) Create feature branch (if not exists), 2) Stage and commit changes with descriptive message, 3) Push to remote, 4) Optionally create PR or prepare for human review. Integrate with issue closer to link commits to issues.","acceptance_criteria":"- Git branch creation/detection\n- Automatic staging of changes\n- Commit message generation (linked to issues)\n- Push to remote support\n- PR creation (via gh CLI or manual prep)\n- Integration with issue workflow\n- Rollback/cleanup on failures","status":"open","priority":1,"issue_type":"epic","created_at":"2025-10-13T21:05:19.449252-07:00","updated_at":"2025-10-14T12:36:26.522119-07:00","dependencies":[{"issue_id":"vc-4","depends_on_id":"vc-2","type":"blocks","created_at":"2025-10-13T21:05:19.450149-07:00","created_by":"import"}]}
{"id":"vc-40","title":"Handle missing issues gracefully in DetectCycles","description":"The DetectCycles function in postgres.go silently skips issues that are in the cycle path but cannot be fetched from the database (lines 870-874). This could hide data integrity issues.\n\nCurrent code:\nfor _, issueID := range cp.issueIDs {\n    issue, ok := issueMap[issueID]\n    if !ok {\n        continue  // Silently skip missing issues\n    }\n    cycleIssues = append(cycleIssues, issue)\n}\n\nIf an issue appears in a dependency cycle but doesn't exist in the issues table, this is a data integrity problem that should be logged or reported, not silently ignored.","design":"Add logging or error reporting for missing issues in cycles:\n\nOption 1 (Logging):\nfor _, issueID := range cp.issueIDs {\n    issue, ok := issueMap[issueID]\n    if !ok {\n        // Log data integrity issue\n        s.logger.Warn(\"issue in cycle path not found in database\", \"issue_id\", issueID, \"path\", cp.path)\n        continue\n    }\n    cycleIssues = append(cycleIssues, issue)\n}\n\nOption 2 (Error return):\nReturn an error if any issue in a cycle path is missing, indicating data corruption.\n\nRecommendation: Option 1 (logging) is better - we still want to detect and report other cycles even if one has data integrity issues.","acceptance_criteria":"- Add logging for missing issues in cycle paths\n- Log includes issue ID and full cycle path for debugging\n- Function continues processing other cycles\n- Does not break existing functionality\n- Code compiles successfully","status":"closed","priority":3,"issue_type":"bug","created_at":"2025-10-14T00:59:27.400123-07:00","updated_at":"2025-10-14T12:36:26.522327-07:00","closed_at":"2025-10-14T02:29:06.340837-07:00"}
{"id":"vc-41","title":"Use deterministic ordering in DetectCycles for consistent results","description":"The DetectCycles function in postgres.go builds issueIDList from a map using range iteration (lines 836-839), which has non-deterministic order in Go:\n\nissueIDList := make([]string, 0, len(uniqueIssueIDs))\nfor id := range uniqueIssueIDs {\n    issueIDList = append(issueIDList, id)\n}\n\nWhile this doesn't affect correctness, it means the SQL query parameters and results can appear in different orders across runs, making debugging harder and test results non-deterministic.","design":"Sort the issue ID list before building the query:\n\nissueIDList := make([]string, 0, len(uniqueIssueIDs))\nfor id := range uniqueIssueIDs {\n    issueIDList = append(issueIDList, id)\n}\nsort.Strings(issueIDList)  // Add deterministic ordering\n\nThis ensures:\n1. SQL queries are consistent across runs\n2. Test results are deterministic\n3. Debugging is easier (logs show same order)\n4. No performance impact (sorting small lists is fast)\n\nNote: The cycles themselves are already ordered by the SQL query's ORDER BY clause, so this only affects the intermediate issue fetching.","acceptance_criteria":"- Import sort package\n- Sort issueIDList after building from map\n- SQL queries use consistent parameter order\n- Tests produce deterministic results\n- Code compiles successfully","status":"closed","priority":3,"issue_type":"bug","created_at":"2025-10-14T00:59:38.807672-07:00","updated_at":"2025-10-14T12:36:26.522533-07:00","closed_at":"2025-10-14T02:28:59.227016-07:00"}
{"id":"vc-42","title":"Empty Backend string should default to sqlite in NewStorage","description":"In storage.go NewStorage() function, when cfg.Backend is an empty string, the switch statement falls through to the default case and returns an error: 'unsupported backend:  (must be 'sqlite' or 'postgres')'.\n\nThis is inconsistent with DefaultConfig() which sets Backend='sqlite' as the default. Users might pass a Config with Backend=\"\" expecting it to use the default.\n\nCurrent behavior at lines 111-173:\nswitch cfg.Backend {\ncase \"sqlite\": ...\ncase \"postgres\": ...\ndefault:\n    return nil, fmt.Errorf(\"unsupported backend: %s...\", cfg.Backend)\n}\n\nWhen Backend=\"\", this returns an error instead of defaulting to sqlite.","design":"Add explicit handling for empty Backend string before the switch statement:\n\nif cfg.Backend == \"\" {\n    cfg.Backend = \"sqlite\"\n}\n\nswitch cfg.Backend {\ncase \"sqlite\": ...\ncase \"postgres\": ...\ndefault: ...\n}\n\nThis matches the behavior of DefaultConfig() which uses sqlite as the default backend.","acceptance_criteria":"- Empty Backend string defaults to \"sqlite\"\n- Error message still shown for invalid backend names\n- DefaultConfig() and NewStorage() have consistent default behavior\n- Code compiles successfully","status":"closed","priority":2,"issue_type":"bug","created_at":"2025-10-14T01:22:31.28857-07:00","updated_at":"2025-10-14T12:49:22.523728-07:00","closed_at":"2025-10-14T12:49:22.523728-07:00"}
{"id":"vc-43","title":"Remove duplicate default logic in NewStorage postgres path","description":"In storage.go NewStorage() function, PostgreSQL connection pool defaults are duplicated in two places:\n\n1. storage.DefaultConfig() sets defaults at lines 87-101\n2. NewStorage() re-applies defaults at lines 149-167\n\nThis creates maintenance burden - if postgres.DefaultConfig() changes, NewStorage() must also be updated. The defaults could drift out of sync.\n\nCurrent code:\n// Build postgres config\npgCfg := \u0026postgres.Config{\n    Host: cfg.Host,\n    MaxConns: cfg.MaxConns,  // Might be 0\n    ...\n}\n\n// Apply defaults if not set\nif pgCfg.MaxConns == 0 {\n    pgCfg.MaxConns = 25  // Hardcoded duplicate\n}\n\nThis duplicates the default value of 25 that's already in postgres.DefaultConfig().","design":"Use postgres.DefaultConfig() as the base and merge user-provided values:\n\n// Start with postgres defaults\npgCfg := postgres.DefaultConfig()\n\n// Override with user-provided values\npgCfg.Host = cfg.Host\npgCfg.Port = cfg.Port\npgCfg.Database = cfg.Database\npgCfg.User = cfg.User\npgCfg.Password = cfg.Password\n\n// Only override pool settings if explicitly set (non-zero)\nif cfg.SSLMode != \"\" {\n    pgCfg.SSLMode = cfg.SSLMode\n}\nif cfg.MaxConns != 0 {\n    pgCfg.MaxConns = cfg.MaxConns\n}\n// ... etc\n\nThis ensures postgres.DefaultConfig() is the single source of truth for defaults.","acceptance_criteria":"- Remove duplicate default values from NewStorage()\n- Use postgres.DefaultConfig() as base for building pgCfg\n- User-provided values override defaults\n- Defaults only exist in one place (postgres.DefaultConfig)\n- Code compiles successfully","status":"closed","priority":2,"issue_type":"bug","created_at":"2025-10-14T01:22:42.858746-07:00","updated_at":"2025-10-14T12:36:26.522979-07:00","closed_at":"2025-10-14T11:16:50.392733-07:00"}
{"id":"vc-44","title":"Document SQLite/PostgreSQL context parameter inconsistency","description":"The SQLite and PostgreSQL backend constructors have inconsistent signatures:\n\n- sqlite.New(path string) (*SQLiteStorage, error)  // No context\n- postgres.New(ctx context.Context, cfg *Config) (*PostgresStorage, error)  // Takes context\n\nThis inconsistency is visible in NewStorage() at lines 117 vs 169:\nreturn sqlite.New(cfg.Path)      // No context passed\nreturn postgres.New(ctx, pgCfg)  // Context passed\n\nThis is existing technical debt in the backend implementations, not something created by vc-21. However, it should be documented as a known issue.\n\nImpact:\n- Inconsistent API design between backends\n- SQLite can't respect context cancellation during initialization\n- Makes it harder to swap backends (different function signatures)","design":"Add a comment in storage.go documenting this inconsistency:\n\n// NewStorage creates a new storage backend based on configuration\n// Note: SQLite backend does not accept a context parameter, only PostgreSQL does.\n// This is a known API inconsistency between the backends.\nfunc NewStorage(ctx context.Context, cfg *Config) (Storage, error) {\n    ...\n}\n\nOptionally create a follow-up issue to fix the backend implementations:\n- Update sqlite.New() to accept context\n- Use context for initialization operations\n- Make both backends consistent","acceptance_criteria":"- Comment added documenting the context parameter inconsistency\n- Explains why sqlite.New() doesn't receive ctx\n- Optional: Create follow-up issue to fix sqlite.New() signature","status":"closed","priority":2,"issue_type":"task","created_at":"2025-10-14T01:22:55.764305-07:00","updated_at":"2025-10-14T12:36:26.523178-07:00","closed_at":"2025-10-14T11:16:22.70806-07:00"}
{"id":"vc-45","title":"DefaultConfig should only populate fields for selected backend","description":"In storage.go, DefaultConfig() populates fields for both SQLite and PostgreSQL backends, even though only one will be used:\n\nreturn \u0026Config{\n    Backend:         \"sqlite\",\n    Path:            \".beads/vc.db\",\n    Host:            \"localhost\",    // PostgreSQL fields\n    Port:            5432,\n    Database:        \"vc\",\n    User:            \"vc\",\n    MaxConns:        25,\n    // ... etc\n}\n\nWhen Backend=\"sqlite\", the PostgreSQL fields (Host, Port, Database, User, MaxConns, etc.) are unused but still allocated.\n\nIssues:\n- Wastes memory for unused fields\n- Confusing: why does a SQLite config have \"User\" and \"Port\" set?\n- Makes config serialization/display messy (shows irrelevant fields)\n\nThis is a minor issue but reduces clarity.","design":"Option 1 (simpler): Keep current behavior, add documentation\n- Document that Config contains fields for all backends\n- Note that only relevant fields are used based on Backend value\n\nOption 2 (cleaner): Make backend-specific defaults\n- Create DefaultSQLiteConfig() and DefaultPostgresConfig() functions\n- DefaultConfig() just returns DefaultSQLiteConfig()\n- Users can call the specific one they need\n\nRecommendation: Option 1 for now (just document), Option 2 if we add more backends.","acceptance_criteria":"- Add comment explaining Config contains fields for all backends\n- Document that irrelevant fields are ignored based on Backend value\n- Optional: Consider backend-specific config functions for future","status":"open","priority":3,"issue_type":"task","created_at":"2025-10-14T01:23:16.765641-07:00","updated_at":"2025-10-14T12:36:26.523416-07:00"}
{"id":"vc-46","title":"Add validation that Backend matches populated config fields","description":"In storage.go, there's no validation that the Backend field matches the populated configuration fields. This allows invalid configurations:\n\nExample 1: Backend=\"sqlite\" but PostgreSQL fields populated\ncfg := \u0026Config{\n    Backend: \"sqlite\",\n    Path: \".beads/vc.db\",\n    Host: \"localhost\",  // Irrelevant for SQLite\n    Port: 5432,\n    Database: \"vc\",\n}\n\nExample 2: Backend=\"postgres\" but Path populated\ncfg := \u0026Config{\n    Backend: \"postgres\",\n    Path: \".beads/vc.db\",  // Irrelevant for PostgreSQL\n    Host: \"localhost\",\n    Port: 5432,\n}\n\nNewStorage() will work but silently ignore the wrong fields. This makes debugging configuration issues harder - users won't know why their Host setting isn't working when they meant to use postgres but accidentally set Backend=\"sqlite\".","design":"Add validation in NewStorage() before the switch statement:\n\n// Validate config consistency\nif cfg.Backend == \"sqlite\" {\n    if cfg.Host \\!= \"\" || cfg.Port \\!= 0 {\n        // Option 1: Warning (log)\n        log.Warn(\"PostgreSQL fields set but Backend is sqlite, ignoring\")\n        \n        // Option 2: Error (strict)\n        return nil, fmt.Errorf(\"Backend is sqlite but PostgreSQL fields are set\")\n    }\n}\n\nRecommendation: Option 1 (warning) for now, since Config is a flat struct. If we add more backends, consider splitting into backend-specific config types.","acceptance_criteria":"- Add validation checking Backend matches populated fields\n- Either log warning or return error for mismatches\n- Document which fields are relevant for which backend\n- Code compiles successfully","status":"open","priority":3,"issue_type":"task","created_at":"2025-10-14T01:23:31.143189-07:00","updated_at":"2025-10-14T12:36:26.523838-07:00"}
{"id":"vc-47","title":"Normalize Backend string to lowercase before comparison in NewStorage","description":"In storage.go NewStorage() function, the Backend field is compared case-sensitively:\n\nswitch cfg.Backend {\ncase \"sqlite\":\n    ...\ncase \"postgres\":\n    ...\n}\n\nThis means \"SQLite\", \"SQLITE\", \"Postgres\", \"PostgreSQL\", etc. would all fail with 'unsupported backend' error.\n\nWhile the documentation says Backend should be \"sqlite\" or \"postgres\", users might naturally type \"SQLite\" or \"PostgreSQL\". Case-insensitive matching would be more user-friendly.\n\nCurrent behavior:\n- \"sqlite\" ✓ works\n- \"SQLite\" ✗ error\n- \"postgres\" ✓ works  \n- \"PostgreSQL\" ✗ error\n\nExpected behavior: All should work.","design":"Normalize Backend to lowercase before the switch:\n\nfunc NewStorage(ctx context.Context, cfg *Config) (Storage, error) {\n    if cfg == nil {\n        cfg = DefaultConfig()\n    }\n    \n    // Normalize backend name to lowercase\n    backend := strings.ToLower(cfg.Backend)\n    \n    // Validate backend type\n    switch backend {\n    case \"sqlite\":\n        ...\n    case \"postgres\":\n        ...\n    default:\n        return nil, fmt.Errorf(\"unsupported backend: %s (must be 'sqlite' or 'postgres')\", cfg.Backend)\n    }\n}\n\nNote: Keep original cfg.Backend in error message so user sees what they actually typed.","acceptance_criteria":"- Add strings.ToLower() before switch statement\n- All case variations of sqlite/postgres work\n- Error message shows original (non-normalized) Backend value\n- Code compiles successfully","status":"open","priority":3,"issue_type":"task","created_at":"2025-10-14T01:23:42.844679-07:00","updated_at":"2025-10-14T12:36:26.524086-07:00"}
{"id":"vc-48","title":"Fix race condition in UpdateExecutionState using atomic UPDATE","description":"UpdateExecutionState in postgres/execution_state.go:129-147 has a race condition. It reads current state with GetExecutionState, validates transition, then updates. Between read and update, another transaction could modify the state.\n\nCurrent flow:\n1. GetExecutionState (read)\n2. Validate transition\n3. UPDATE (write)\n\nThis is a check-then-act race condition.","design":"Replace the read-validate-update pattern with a single atomic UPDATE that includes the validation:\n\n```go\nquery := `\n    UPDATE issue_execution_state\n    SET state = $1, updated_at = $2\n    WHERE issue_id = $3 AND state = $4\n`\nresult, err := s.pool.Exec(ctx, query, newState, time.Now(), issueID, expectedCurrentState)\nif result.RowsAffected() == 0 {\n    // Either issue not found OR state changed (concurrent modification)\n    // Need to distinguish these cases\n}\n```\n\nAlternative: Use SELECT FOR UPDATE in a transaction to lock the row.","acceptance_criteria":"- UpdateExecutionState prevents concurrent state modifications\n- Invalid transitions still return appropriate errors\n- No performance regression\n- Tests verify concurrent update behavior","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-10-14T03:35:01.448793-07:00","updated_at":"2025-10-14T12:36:26.524287-07:00","closed_at":"2025-10-14T03:37:25.948754-07:00"}
{"id":"vc-49","title":"Remove redundant claim check in ClaimIssue","description":"ClaimIssue in postgres/execution_state.go:25-33 performs a redundant SELECT to check if issue is already claimed before the INSERT. The INSERT itself will fail with a unique constraint violation (error 23505) if the issue is already claimed, which we already handle at lines 66-70.\n\nThe redundant check adds an extra database roundtrip without providing additional safety.","design":"Remove lines 25-33:\n```go\n// Check if issue is already claimed\nvar existingExecutor string\nerr = tx.QueryRow(ctx, \"SELECT executor_instance_id FROM issue_execution_state WHERE issue_id = $1\", issueID).Scan(\u0026existingExecutor)\nif err != nil \u0026\u0026 err != pgx.ErrNoRows {\n    return fmt.Errorf(\"failed to check execution state: %w\", err)\n}\nif err == nil {\n    return fmt.Errorf(\"issue %s is already claimed by another executor\", issueID)\n}\n```\n\nThe existing constraint check at lines 66-70 is sufficient and atomic.","acceptance_criteria":"- ClaimIssue still prevents double-claiming\n- One fewer database roundtrip per claim\n- All existing tests still pass\n- Error message for already-claimed issues remains clear","status":"closed","priority":2,"issue_type":"task","created_at":"2025-10-14T03:35:10.838747-07:00","updated_at":"2025-10-14T12:36:26.524686-07:00","closed_at":"2025-10-14T11:16:01.574132-07:00"}
{"id":"vc-5","title":"Beads Integration and Executor Tables","description":"Foundation work: Extend Beads with VC-specific fields and executor tables. This is the base layer that all other phases depend on.","design":"Add: 1) discovered-from dependency type (already in Beads), 2) design/acceptance_criteria/notes fields (already in Beads), 3) executor_instances table for tracking worker instances, 4) issue_execution_state table for checkpointing/resumption, 5) Ensure PostgreSQL backend works alongside SQLite","acceptance_criteria":"- discovered-from dependency type verified working\n- design, acceptance_criteria, notes fields verified working\n- executor_instances table created and schema documented\n- issue_execution_state table created with checkpoint support\n- PostgreSQL backend tested (while keeping SQLite as default)\n- Migration/initialization scripts created\n- All beads tests passing with new tables","notes":"Progress: 2 of 6 child tasks completed (vc-10, vc-11). executor_instances table fully implemented with type-safe enum and validation. Next: vc-12 (issue_execution_state table).","status":"closed","priority":0,"issue_type":"epic","created_at":"2025-10-13T21:05:19.449345-07:00","updated_at":"2025-10-14T13:10:24.885139-07:00","closed_at":"2025-10-14T13:10:24.885139-07:00","dependencies":[{"issue_id":"vc-5","depends_on_id":"vc-10","type":"parent-child","created_at":"2025-10-13T21:22:52.23331-07:00","created_by":"stevey"},{"issue_id":"vc-5","depends_on_id":"vc-11","type":"parent-child","created_at":"2025-10-13T21:22:52.237887-07:00","created_by":"stevey"},{"issue_id":"vc-5","depends_on_id":"vc-12","type":"parent-child","created_at":"2025-10-13T21:22:52.242491-07:00","created_by":"stevey"},{"issue_id":"vc-5","depends_on_id":"vc-13","type":"parent-child","created_at":"2025-10-13T21:22:52.247016-07:00","created_by":"stevey"},{"issue_id":"vc-5","depends_on_id":"vc-14","type":"parent-child","created_at":"2025-10-13T21:22:52.251938-07:00","created_by":"stevey"},{"issue_id":"vc-5","depends_on_id":"vc-15","type":"parent-child","created_at":"2025-10-13T21:22:52.256877-07:00","created_by":"stevey"}]}
{"id":"vc-50","title":"Make GROUP BY explicit in GetBlockedIssues","description":"GetBlockedIssues in postgres/ready.go:93 uses 'GROUP BY i.id' which works because i.id is a primary key, but some PostgreSQL configurations require all non-aggregated SELECT columns to be explicitly listed in GROUP BY.\n\nThe schema view (schema.go:92-94) does this correctly by listing all columns.","design":"Replace:\n```go\nGROUP BY i.id\n```\n\nWith:\n```go\nGROUP BY i.id, i.title, i.description, i.design, i.acceptance_criteria, i.notes,\n         i.status, i.priority, i.issue_type, i.assignee, i.estimated_minutes,\n         i.created_at, i.updated_at, i.closed_at\n```\n\nThis matches the pattern used in the blocked_issues view in schema.go.","acceptance_criteria":"- Query works on all PostgreSQL configurations\n- No change in query results\n- Matches schema view pattern\n- All tests pass","status":"closed","priority":2,"issue_type":"task","created_at":"2025-10-14T03:35:19.936792-07:00","updated_at":"2025-10-14T12:36:26.52505-07:00","closed_at":"2025-10-14T11:15:40.379072-07:00"}
{"id":"vc-51","title":"Add PostgreSQL integration tests for execution state operations","description":"The PostgreSQL backend execution state and ready work operations lack integration tests. Currently we only have SQLite tests. This creates a gap in test coverage for PostgreSQL-specific behavior:\n\n- JSONB checkpoint data handling\n- array_agg in GetBlockedIssues\n- PostgreSQL-specific error codes (23505)\n- COUNT(*) FILTER syntax\n- EXTRACT(EPOCH) for timestamps\n\nThe SQLite tests verify the business logic, but not the PostgreSQL-specific implementation details.","design":"Create postgres/execution_state_test.go and postgres/ready_test.go that:\n\n1. Use testcontainers or similar to spin up PostgreSQL\n2. Port key tests from sqlite/execution_state_test.go\n3. Add PostgreSQL-specific tests:\n   - JSONB marshaling/unmarshaling edge cases\n   - array_agg with various data\n   - Concurrent ClaimIssue attempts (race testing)\n   - Verify error codes match expectations\n\nFollow the pattern in sqlite tests but adapt for PostgreSQL connection handling.","acceptance_criteria":"- PostgreSQL-specific tests exist and pass\n- Tests cover JSONB, array_agg, error codes\n- Tests use real PostgreSQL (not mocks)\n- CI can run tests (either with testcontainers or postgres service)\n- Test coverage metrics show adequate coverage","status":"open","priority":3,"issue_type":"task","created_at":"2025-10-14T03:35:31.600395-07:00","updated_at":"2025-10-14T12:36:26.525236-07:00"}
{"id":"vc-52","title":"Add defensive handling for array_agg null in GetBlockedIssues","description":"GetBlockedIssues in postgres/ready.go:86 uses array_agg(d.depends_on_id) which could theoretically return {NULL} in edge cases. While the JOINs should prevent this, defensive programming suggests handling it.\n\nCurrently we scan directly into []string at line 107. If array_agg somehow returns {NULL}, we'd get a slice with one empty/null element.","design":"Add validation after scanning blockerIDs:\n\n```go\nissue.BlockedBy = blockerIDs\n\n// Filter out any null/empty blocker IDs (defensive)\nif len(blockerIDs) == 1 \u0026\u0026 blockerIDs[0] == \"\" {\n    issue.BlockedBy = []string{}\n}\n```\n\nOr use COALESCE in the query:\n```sql\nCOALESCE(array_agg(d.depends_on_id), ARRAY[]::text[]) as blocker_ids\n```\n\nThe query approach is cleaner.","acceptance_criteria":"- GetBlockedIssues handles edge cases gracefully\n- No null/empty strings in BlockedBy arrays\n- Existing behavior unchanged for normal cases\n- Add test case for edge condition if possible","status":"open","priority":3,"issue_type":"task","created_at":"2025-10-14T03:35:44.288451-07:00","updated_at":"2025-10-14T12:36:26.525442-07:00"}
{"id":"vc-53","title":"Fix double ReleaseIssue call in executor","description":"Bug: executeIssue() was calling ReleaseIssue() twice - once in the error path (via releaseIssueWithError) and again unconditionally at the end. This caused 'execution state not found' errors.\n\nFix: Moved ReleaseIssue() call inside the success branch only, since releaseIssueWithError() already handles the error path.","acceptance_criteria":"\n- ReleaseIssue only called once per execution\n- No 'execution state not found' errors\n- Error path properly releases via releaseIssueWithError\n- Success path properly releases before return\n","status":"closed","priority":2,"issue_type":"bug","created_at":"2025-10-14T14:12:35.515401-07:00","updated_at":"2025-10-14T14:12:43.113528-07:00","closed_at":"2025-10-14T14:12:43.113528-07:00"}
{"id":"vc-54","title":"Fix race condition in agent output capture","description":"The agent output capture goroutines have a race condition where console printing happens outside the mutex lock.\n\nLocation: internal/executor/agent.go:207-208 and 229-230\n\nIssue:\n- Line 207: fmt.Println(line) happens outside mutex\n- Line 229: fmt.Fprintln(os.Stderr, line) happens outside mutex\n- The mutex-protected append and the console print can interleave\n\nThis could cause output to appear out of order on the console vs. what's captured in memory.","design":"Move the console printing inside the mutex:\n\n// Capture stdout\ngo func() {\n    defer wg.Done()\n    scanner := bufio.NewScanner(a.stdout)\n    for scanner.Scan() {\n        line := scanner.Text()\n        a.mu.Lock()\n        \n        if len(a.result.Output) \u003c maxOutputLines {\n            a.result.Output = append(a.result.Output, line)\n            // Print inside mutex to ensure ordering\n            fmt.Println(line)\n        } else if len(a.result.Output) == maxOutputLines {\n            a.result.Output = append(a.result.Output, \"[... truncated ...]\")\n        }\n        \n        a.mu.Unlock()\n    }\n}()\n\nSame pattern for stderr capture.","acceptance_criteria":"\n- Console output order matches captured output order\n- No race conditions detected by go test -race\n- Output capture still works correctly\n","status":"closed","priority":2,"issue_type":"bug","created_at":"2025-10-14T14:14:56.593386-07:00","updated_at":"2025-10-14T14:19:31.003811-07:00","closed_at":"2025-10-14T14:19:31.003811-07:00"}
{"id":"vc-55","title":"Improve agent process cleanup and verification","description":"When agent execution times out, we call Kill() but don't verify the process actually died.\n\nLocation: internal/executor/agent.go:140\n\nIssue:\n- Kill() may fail silently\n- Process could become a zombie\n- No verification that kill succeeded\n\nThis could lead to orphaned processes accumulating over time.","design":"After calling Kill(), wait briefly and verify the process is dead:\n\na.Kill()\n// Give process time to die\ntime.Sleep(100 * time.Millisecond)\nif a.cmd.Process != nil {\n    // Check if process still exists\n    if err := a.cmd.Process.Signal(syscall.Signal(0)); err == nil {\n        // Process still alive - escalate to SIGKILL on Unix\n        a.cmd.Process.Signal(syscall.SIGKILL)\n    }\n}\n\nPlatform-specific considerations:\n- Unix: Can use SIGKILL if SIGTERM fails\n- Windows: Process.Kill() is already forceful\n\nConsider adding a ProcessManager to track spawned agents for cleanup on executor shutdown.","acceptance_criteria":"\n- Kill() failures are detected and logged\n- Zombie processes are prevented\n- Process cleanup verified before returning\n- Consider adding agent process registry\n","status":"open","priority":3,"issue_type":"task","created_at":"2025-10-14T14:15:10.60387-07:00","updated_at":"2025-10-14T14:15:10.60387-07:00"}
{"id":"vc-56","title":"Add logging for claim race conditions","description":"When ClaimIssue fails due to race condition (another executor claimed it first), we silently return nil. This makes it hard to debug multi-executor scenarios.\n\nLocation: internal/executor/executor.go:218-221\n\nCurrent behavior:\nif err := e.store.ClaimIssue(ctx, issue.ID, e.instanceID); err != nil {\n    return nil  // Silent ignore\n}\n\nThis is correct behavior (race conditions are expected), but we should log for observability.","design":"Add debug-level logging when claim fails:\n\nif err := e.store.ClaimIssue(ctx, issue.ID, e.instanceID); err != nil {\n    fmt.Fprintf(os.Stderr, \"debug: issue %s already claimed: %v\\n\", issue.ID, err)\n    return nil\n}\n\nLater, when adding structured logging:\n- Use debug level (not error)\n- Include issue ID and executor instance ID\n- Track claim race metrics","acceptance_criteria":"\n- Claim failures logged at debug level\n- Log includes issue ID and reason\n- Does not spam logs under normal operation\n- Helps debug multi-executor scenarios\n","status":"open","priority":3,"issue_type":"task","created_at":"2025-10-14T14:15:24.430065-07:00","updated_at":"2025-10-14T14:15:24.430065-07:00"}
{"id":"vc-6","title":"Issue Processor Event Loop","description":"Build the event loop that claims and executes issues via coding agents. No AI supervision yet - just mechanical claiming, spawning agents, and updating status. The core execution engine.","design":"Port IssueWorkflowExecutor pattern: 1) Atomic claiming with PostgreSQL FOR UPDATE SKIP LOCKED, 2) Spawn Cody/Claude Code with -stream-json, 3) Parse agent output and update issue status, 4) Handle epic completion detection, 5) Support pause/resume/abort. Pure orchestration layer with no AI decision-making yet.","acceptance_criteria":"- Event loop running continuously\n- Atomic issue claiming from ready work queue\n- Cody/Claude Code spawning and lifecycle management\n- Agent output parsing and status updates\n- Epic completion detection (all children closed)\n- Pause/resume/abort commands working\n- Basic error handling and retries\n- 'vc execute' command working end-to-end","notes":"Completed implementation:\n- Executor event loop with continuous polling\n- Atomic issue claiming via ClaimIssue\n- Agent spawning (Cody/Claude Code) with lifecycle management  \n- Output parsing and status updates\n- Pause/resume/abort via signal handling\n- Epic completion detection\n- 'vc execute' CLI command\n\nAll acceptance criteria met. Built and tested successfully.","status":"closed","priority":0,"issue_type":"epic","created_at":"2025-10-13T21:05:19.449438-07:00","updated_at":"2025-10-14T13:52:08.417303-07:00","closed_at":"2025-10-14T13:52:08.417303-07:00","dependencies":[{"issue_id":"vc-6","depends_on_id":"vc-5","type":"blocks","created_at":"2025-10-13T21:05:19.450237-07:00","created_by":"import"}]}
{"id":"vc-7","title":"AI Supervision (Assess and Analyze)","description":"Add AI assessment before execution and AI analysis after execution. This is what makes vc intelligent - AI reviews every task and extracts hidden work. The 'secret sauce' that prevents agents from going off the rails.","design":"Integrate Anthropic Go SDK (Sonnet 4.5): 1) assessIssueState before execution (strategy, steps, risks, confidence), 2) analyzeExecutionResult after execution (completion status, punted items, discovered work, quality issues), 3) Auto-create discovered issues from AI analysis, 4) Log AI confidence and reasoning for debugging. Two AI calls per issue execution.","acceptance_criteria":"- Anthropic Go SDK integrated\n- assessIssueState activity implemented\n- analyzeExecutionResult activity implemented\n- AI confidence scores logged\n- AI reasoning/strategy logged to events\n- Auto-creation of discovered issues working\n- Integration with issue processor (Phase 2)\n- AI costs tracked and logged\n- Fallback handling for AI failures","status":"open","priority":0,"issue_type":"epic","created_at":"2025-10-13T21:05:19.449508-07:00","updated_at":"2025-10-14T12:36:26.525818-07:00","dependencies":[{"issue_id":"vc-7","depends_on_id":"vc-6","type":"blocks","created_at":"2025-10-13T21:05:19.450326-07:00","created_by":"import"}]}
{"id":"vc-8","title":"Quality Gates Enforcement","description":"Enforce quality standards before closing issues. All four gates must pass: go test, golangci-lint, go build. On failure, create blocking issues. Prevents broken code from being marked complete.","design":"After issue execution completes, run quality gate sequence: 1) go test (all tests must pass), 2) golangci-lint (zero lint errors), 3) go build (clean build). On any gate failure, create blocking issue with gate type label, mark original issue as blocked. Quality gates are mechanical - no AI decision making.","acceptance_criteria":"- go test gate implemented\n- golangci-lint gate implemented  \n- go build gate implemented\n- Blocking issue creation on failures\n- Gate failure details captured in blocking issues\n- Original issue status updated to blocked\n- Gate pass/fail logged to events\n- Integration with issue processor\n- Gate results visible in issue show command","status":"open","priority":0,"issue_type":"epic","created_at":"2025-10-13T21:05:19.449594-07:00","updated_at":"2025-10-14T12:36:26.525998-07:00","dependencies":[{"issue_id":"vc-8","depends_on_id":"vc-7","type":"blocks","created_at":"2025-10-13T21:05:19.450421-07:00","created_by":"import"}]}
{"id":"vc-9","title":"REPL Shell and Natural Language Interface","description":"Interactive shell for directing VC. Natural language interface that translates user requests into issues. The 'VibeCoder Primitive': user says 'let's continue' and system resumes from tracker state.","design":"Simple vc command with chat interface: 1) Accept natural language input from user, 2) Use AI to translate requests into issues (create epic, break into children), 3) Show activity feed of agent work, 4) 'let's continue' command resumes from current tracker state (finds ready work). The human\u003c-\u003eAI interaction layer.","acceptance_criteria":"- vc repl command starts interactive shell\n- Natural language input accepted\n- AI translation of requests to issues working\n- Issue/epic creation from natural language\n- Activity feed display in REPL\n- 'let's continue' command implemented\n- Tracker state visibility (what's ready, what's blocked)\n- Exit/quit commands\n- Command history\n- Integration with issue processor and AI supervision","status":"open","priority":0,"issue_type":"epic","created_at":"2025-10-13T21:05:19.449673-07:00","updated_at":"2025-10-14T12:36:26.526169-07:00","dependencies":[{"issue_id":"vc-9","depends_on_id":"vc-8","type":"blocks","created_at":"2025-10-13T21:05:19.450524-07:00","created_by":"import"}]}
