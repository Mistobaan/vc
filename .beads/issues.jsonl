{"id":"vc-1","title":"Activity Feed and Event Streaming","description":"Implement comprehensive event journaling and real-time activity feed for observability. Without this, debugging AI agents is nearly impossible. Must-have before dogfooding.","design":"Event-based system that logs all executor actions, AI assessments, issue state changes, and agent interactions. Provides 'vc executor tail' command for real-time monitoring.","acceptance_criteria":"- Event journal table in database\n- Activity feed CLI command working\n- Real-time tail functionality\n- Integration with issue processor\n- Events logged for: issue claims, AI assessments, executions, quality gates, issue closures","status":"open","priority":0,"issue_type":"epic","created_at":"2025-10-14T23:26:12.227898-07:00","updated_at":"2025-10-14T23:56:05.823034-07:00","dependencies":[{"issue_id":"vc-1","depends_on_id":"vc-9","type":"blocks","created_at":"2025-10-14T23:26:12.280681-07:00","created_by":"auto-import"}]}
{"id":"vc-10","title":"Verify existing Beads fields and add discovered-from dependency type","description":"Quick verification that design, acceptance_criteria, and notes fields work correctly. Add the 'discovered-from' dependency type constant to support tracking work discovered during execution.","design":"1. Write test to verify design/acceptance_criteria/notes fields can be set and retrieved. 2. Add DepDiscoveredFrom constant to internal/types/types.go. 3. Update DependencyType.IsValid() to include new type. 4. Test creating dependencies with discovered-from type.","acceptance_criteria":"- Test confirms design, acceptance_criteria, notes fields work correctly\\n- DepDiscoveredFrom constant added to types\\n- IsValid() function updated\\n- Can create and query dependencies with type 'discovered-from'\\n- Documentation updated","status":"closed","priority":0,"issue_type":"task","created_at":"2025-10-14T23:26:12.228814-07:00","updated_at":"2025-10-14T23:56:05.825601-07:00"}
{"id":"vc-11","title":"Design and implement executor_instances table","description":"Create the executor_instances table to track which executor instances are running. This enables multi-executor coordination and stale instance cleanup.","design":"Schema: instance_id (TEXT PK), hostname (TEXT), pid (INTEGER), status (running/stopped), started_at (DATETIME), last_heartbeat (DATETIME), version (TEXT), metadata (JSON). Add to Storage interface: RegisterInstance(), UpdateHeartbeat(), GetActiveInstances(), CleanupStaleInstances(). Implement in SQLite backend. Add indexes on status and last_heartbeat.","acceptance_criteria":"- executor_instances table created in schema.go\\n- Storage interface methods added\\n- SQLite implementation complete\\n- Registration and heartbeat functions work\\n- Stale instance cleanup logic implemented\\n- Schema documented with comments\\n- Basic unit tests pass","status":"closed","priority":0,"issue_type":"task","created_at":"2025-10-14T23:26:12.229338-07:00","updated_at":"2025-10-14T23:56:05.826163-07:00","dependencies":[{"issue_id":"vc-11","depends_on_id":"vc-10","type":"blocks","created_at":"2025-10-14T23:26:12.281354-07:00","created_by":"auto-import"}]}
{"id":"vc-12","title":"Design and implement issue_execution_state table","description":"Create the issue_execution_state table for checkpoint/resume support. This enables executors to save progress and resume after interruption.","design":"Schema: issue_id (TEXT FK), executor_instance_id (TEXT FK), state (claimed/assessing/executing/analyzing/gates/completed), checkpoint_data (JSON), started_at (DATETIME), updated_at (DATETIME). Add atomic ClaimIssue() that inserts execution_state row and updates issue status. Add SaveCheckpoint(), GetCheckpoint(), ResumeFromCheckpoint(). State machine: claimed → assessing → executing → analyzing → gates → completed.","acceptance_criteria":"- issue_execution_state table created in schema.go\\n- Atomic ClaimIssue() prevents double-claiming\\n- SaveCheckpoint()/GetCheckpoint() work with JSON data\\n- State transitions enforced\\n- Foreign keys to issues and executor_instances\\n- Schema documented\\n- Unit tests for claim and checkpoint operations","status":"closed","priority":0,"issue_type":"task","created_at":"2025-10-14T23:26:12.229805-07:00","updated_at":"2025-10-14T23:56:05.827098-07:00","dependencies":[{"issue_id":"vc-12","depends_on_id":"vc-11","type":"blocks","created_at":"2025-10-14T23:26:12.281848-07:00","created_by":"auto-import"}]}
{"id":"vc-13","title":"Implement PostgreSQL backend","description":"Implement PostgreSQL storage backend. Port all schemas (issues, dependencies, executor tables) to PostgreSQL DDL and implement the Storage interface for postgres.","design":"Create internal/storage/postgres/ package mirroring sqlite structure. Port schema DDL to PostgreSQL (use JSONB for metadata/checkpoints). Implement all Storage interface methods. Add connection pooling with pgx. Create factory function in storage package to return correct backend based on config. Test switching between backends.","acceptance_criteria":"- postgres package created with full Storage implementation\\n- All schemas ported to PostgreSQL DDL\\n- Connection pooling configured\\n- Backend factory function works\\n- Can switch between SQLite and PostgreSQL via config\\n- All basic operations work on PostgreSQL\\n- Connection lifecycle handled correctly","status":"in_progress","priority":0,"issue_type":"task","created_at":"2025-10-14T23:26:12.230266-07:00","updated_at":"2025-10-14T23:56:05.827719-07:00","dependencies":[{"issue_id":"vc-13","depends_on_id":"vc-12","type":"blocks","created_at":"2025-10-14T23:26:12.282317-07:00","created_by":"auto-import"},{"issue_id":"vc-13","depends_on_id":"vc-16","type":"parent-child","created_at":"2025-10-14T23:26:12.282725-07:00","created_by":"auto-import"},{"issue_id":"vc-13","depends_on_id":"vc-17","type":"parent-child","created_at":"2025-10-14T23:26:12.283107-07:00","created_by":"auto-import"},{"issue_id":"vc-13","depends_on_id":"vc-18","type":"parent-child","created_at":"2025-10-14T23:26:12.283456-07:00","created_by":"auto-import"},{"issue_id":"vc-13","depends_on_id":"vc-19","type":"parent-child","created_at":"2025-10-14T23:26:12.283816-07:00","created_by":"auto-import"},{"issue_id":"vc-13","depends_on_id":"vc-20","type":"parent-child","created_at":"2025-10-14T23:26:12.284212-07:00","created_by":"auto-import"},{"issue_id":"vc-13","depends_on_id":"vc-21","type":"parent-child","created_at":"2025-10-14T23:26:12.284792-07:00","created_by":"auto-import"}]}
{"id":"vc-14","title":"Create migration and initialization scripts","description":"Create scripts/functions to initialize fresh databases and handle schema migrations for both SQLite and PostgreSQL.","design":"Add InitDatabase() function that creates all tables with current schema. Create internal/storage/migrations package. Design simple migration system: version table, sequential numbered migrations, up/down support. Create scripts/init-db.sh for CLI usage. Document bootstrap process in CLAUDE.md. Consider using golang-migrate or similar for production migrations.","acceptance_criteria":"- InitDatabase() creates all tables for both backends\\n- Migration framework designed and documented\\n- scripts/init-db.sh can bootstrap fresh database\\n- Version tracking table exists\\n- At least one test migration created and works\\n- Bootstrap process documented\\n- Works for both SQLite and PostgreSQL","status":"open","priority":0,"issue_type":"task","created_at":"2025-10-14T23:26:12.230729-07:00","updated_at":"2025-10-14T23:56:05.828402-07:00","dependencies":[{"issue_id":"vc-14","depends_on_id":"vc-13","type":"blocks","created_at":"2025-10-14T23:26:12.285221-07:00","created_by":"auto-import"}]}
{"id":"vc-15","title":"Integration tests for executor functionality","description":"Write integration tests validating the full executor table functionality, including multi-executor scenarios, claim/checkpoint/resume flows, and both database backends.","design":"Create internal/storage/integration_test.go. Test scenarios: 1) Multiple executors claiming different issues (no conflicts), 2) Claim race condition handling, 3) Checkpoint save and restore, 4) Stale instance cleanup, 5) Resume after interruption, 6) All above on both SQLite and PostgreSQL. Use table-driven tests to run same scenarios on both backends.","acceptance_criteria":"- Integration test file created\\n- Multi-executor claim scenarios pass\\n- Race condition tests pass (no double-claiming)\\n- Checkpoint/resume cycle works\\n- Stale instance cleanup verified\\n- All tests pass on SQLite\\n- All tests pass on PostgreSQL\\n- Test coverage documented","status":"open","priority":0,"issue_type":"task","created_at":"2025-10-14T23:26:12.231198-07:00","updated_at":"2025-10-14T23:56:05.829052-07:00","dependencies":[{"issue_id":"vc-15","depends_on_id":"vc-14","type":"blocks","created_at":"2025-10-14T23:26:12.285742-07:00","created_by":"auto-import"},{"issue_id":"vc-15","depends_on_id":"vc-6","type":"blocks","created_at":"2025-10-14T23:26:12.286173-07:00","created_by":"auto-import"}]}
{"id":"vc-16","title":"Create postgres.go with connection pooling and base structure","description":"Create internal/storage/postgres/postgres.go with PostgresStorage struct, connection pooling via pgx.Pool, New() constructor, and Close() method. Set up basic structure mirroring SQLite implementation.","design":"Use pgx/v5 connection pool. Connection string: postgres://user:pass@host:port/dbname. Configure pool size, timeouts. Initialize schema on New(). Implement proper connection lifecycle.","acceptance_criteria":"- PostgresStorage struct with pgx.Pool\\n- New() constructor with connection pooling\\n- Schema initialization on startup\\n- Close() method for cleanup\\n- Connection string parsing\\n- Pool configuration (max conns, timeouts)\\n- Error handling for connection failures","status":"closed","priority":0,"issue_type":"task","created_at":"2025-10-14T23:26:12.231597-07:00","updated_at":"2025-10-14T23:56:05.829466-07:00"}
{"id":"vc-17","title":"Implement PostgreSQL issue operations","description":"Implement issue CRUD operations in PostgreSQL: CreateIssue, GetIssue, UpdateIssue, CloseIssue, SearchIssues. Port from SQLite implementation, converting ? placeholders to $1, $2, etc.","design":"Port issue operations from internal/storage/sqlite/sqlite.go. Use numbered placeholders ($1, $2). Handle ID generation for new issues. Implement field validation. Use transactions where appropriate. Handle NULL values correctly for optional fields (assignee, estimated_minutes, closed_at).","acceptance_criteria":"- CreateIssue() works with ID generation\\n- GetIssue() retrieves issues correctly\\n- UpdateIssue() handles partial updates\\n- CloseIssue() sets status and closed_at\\n- SearchIssues() supports filtering and pagination\\n- Event logging integrated\\n- Validation enforced\\n- Transactions used appropriately","status":"closed","priority":0,"issue_type":"task","created_at":"2025-10-14T23:26:12.23197-07:00","updated_at":"2025-10-14T23:56:05.829859-07:00","dependencies":[{"issue_id":"vc-17","depends_on_id":"vc-16","type":"blocks","created_at":"2025-10-14T23:26:12.286586-07:00","created_by":"auto-import"}]}
{"id":"vc-18","title":"Implement PostgreSQL dependency, label, and event operations","description":"Port dependencies.go, labels.go, and events.go from SQLite to PostgreSQL. Implement AddDependency, RemoveDependency, GetDependencies, GetDependents, GetDependencyTree, DetectCycles for dependencies. AddLabel, RemoveLabel, GetLabels, GetIssuesByLabel for labels. AddComment, GetEvents for events.","design":"Port from SQLite files. Convert ? to $N. Handle foreign key constraints. Implement cycle detection algorithm. Use recursive CTEs for dependency tree queries in PostgreSQL.","acceptance_criteria":"- All dependency operations work\\n- All label operations work\\n- All event operations work\\n- Cycle detection functional\\n- Dependency tree query efficient\\n- Foreign keys enforced\\n- Event logging works","status":"closed","priority":0,"issue_type":"task","created_at":"2025-10-14T23:26:12.232412-07:00","updated_at":"2025-10-14T23:56:05.832058-07:00","dependencies":[{"issue_id":"vc-18","depends_on_id":"vc-17","type":"blocks","created_at":"2025-10-14T23:26:12.286989-07:00","created_by":"auto-import"}]}
{"id":"vc-19","title":"Implement PostgreSQL executor instance operations","description":"Port executor_instances.go from SQLite to PostgreSQL. Implement RegisterInstance, UpdateHeartbeat, GetActiveInstances, CleanupStaleInstances. Handle JSONB metadata field.","design":"Port from sqlite/executor_instances.go. Use JSONB for metadata. Implement upsert pattern for RegisterInstance. Use timestamptz comparisons for stale detection. Handle connection pool correctly.","acceptance_criteria":"- RegisterInstance works with upsert\\n- UpdateHeartbeat updates timestamp\\n- GetActiveInstances filters by status\\n- CleanupStaleInstances handles threshold\\n- JSONB metadata handled correctly\\n- All operations tested","status":"open","priority":0,"issue_type":"task","created_at":"2025-10-14T23:26:12.232807-07:00","updated_at":"2025-10-14T23:56:05.839099-07:00","dependencies":[{"issue_id":"vc-19","depends_on_id":"vc-16","type":"blocks","created_at":"2025-10-14T23:26:12.287362-07:00","created_by":"auto-import"}]}
{"id":"vc-2","title":"Recursive Refinement and Follow-On Missions","description":"The core of 'Engineer-in-a-Box'. AI analyzes execution results and automatically creates follow-on issues for discovered work, punted items, and quality problems. This is what makes vc self-improving instead of just a task executor.","design":"After each issue execution, AI analyzes the result and extracts: 1) Punted work (deferred items), 2) Discovered bugs/issues, 3) Quality problems. Automatically creates child issues with 'discovered-from' dependencies. Executor processes these recursively until all work is complete.","acceptance_criteria":"- analyzeExecutionResult AI activity implemented\n- Automatic issue creation from AI analysis\n- discovered-from dependency type support\n- Punted items labeled and tracked\n- Quality issues create blocking dependencies\n- Recursive processing until convergence\n- Integration with quality gates","status":"open","priority":0,"issue_type":"epic","created_at":"2025-10-14T23:26:12.233234-07:00","updated_at":"2025-10-14T23:56:05.858803-07:00","dependencies":[{"issue_id":"vc-2","depends_on_id":"vc-1","type":"blocks","created_at":"2025-10-14T23:26:12.287879-07:00","created_by":"auto-import"}]}
{"id":"vc-20","title":"Implement PostgreSQL execution state and ready work operations","description":"Port execution_state.go and ready.go from SQLite to PostgreSQL. Implement ClaimIssue, GetExecutionState, UpdateExecutionState, SaveCheckpoint, GetCheckpoint, ReleaseIssue for execution state. Implement GetReadyWork, GetBlockedIssues, GetStatistics for ready work queries. Use JSONB for checkpoint data.","design":"Port from SQLite. Use JSONB for checkpoint_data. Implement atomic ClaimIssue with proper PostgreSQL locking. Use views for ready_issues and blocked_issues queries. Implement statistics aggregation efficiently.","acceptance_criteria":"- ClaimIssue atomic and prevents double-claiming\\n- All execution state operations work\\n- GetReadyWork returns correct issues\\n- GetBlockedIssues identifies blocked work\\n- GetStatistics provides accurate counts\\n- JSONB checkpoint data handled\\n- State machine enforced","status":"open","priority":0,"issue_type":"task","created_at":"2025-10-14T23:26:12.233865-07:00","updated_at":"2025-10-14T23:56:05.85935-07:00","dependencies":[{"issue_id":"vc-20","depends_on_id":"vc-17","type":"blocks","created_at":"2025-10-14T23:26:12.288269-07:00","created_by":"auto-import"},{"issue_id":"vc-20","depends_on_id":"vc-19","type":"blocks","created_at":"2025-10-14T23:26:12.288649-07:00","created_by":"auto-import"}]}
{"id":"vc-21","title":"Create storage factory function for backend selection","description":"Add factory function in internal/storage/storage.go to create correct backend (SQLite or PostgreSQL) based on Config. Enable switching between backends via configuration.","design":"Add NewStorage(config Config) (Storage, error) function. Check config.Backend field. Return sqlite.New() or postgres.New() based on backend. Handle connection string building for PostgreSQL. Validate config before creating backend.","acceptance_criteria":"- NewStorage() factory function works\\n- Selects SQLite when config.Backend='sqlite'\\n- Selects PostgreSQL when config.Backend='postgres'\\n- Config validation implemented\\n- Connection string handling correct\\n- Error messages clear\\n- Can switch backends easily","status":"closed","priority":0,"issue_type":"task","created_at":"2025-10-14T23:26:12.23428-07:00","updated_at":"2025-10-14T23:56:05.859842-07:00","dependencies":[{"issue_id":"vc-21","depends_on_id":"vc-16","type":"blocks","created_at":"2025-10-14T23:26:12.289119-07:00","created_by":"auto-import"}]}
{"id":"vc-22","title":"Fix PostgreSQL ID generation race condition","description":"The getNextID() function in postgres.go has a race condition in multi-executor scenarios. Two executors can both read MAX(id) and get the same nextID, leading to UNIQUE constraint violations.","design":"Options: 1) Use PostgreSQL SEQUENCE for ID generation (most robust), 2) Use atomic database-side ID allocation (SELECT ... FOR UPDATE), 3) Document that each executor should have its own ID range. Recommended: PostgreSQL sequence with 'vc-' prefix using a custom function.","acceptance_criteria":"- ID generation is thread-safe across multiple executor instances\\n- No UNIQUE constraint violations possible\\n- Tests verify concurrent ID generation\\n- Performance acceptable (\u003c 5ms per ID)","status":"open","priority":1,"issue_type":"bug","created_at":"2025-10-14T23:26:12.234677-07:00","updated_at":"2025-10-14T23:56:05.86066-07:00"}
{"id":"vc-23","title":"Fix error handling in getNextID function","description":"The getNextID() function in postgres.go silently ignores errors. On line 134, 'if err \\!= nil \u0026\u0026 err \\!= pgx.ErrNoRows' returns 1 instead of propagating the error. Network failures, permission errors, etc. would be masked.","design":"Change logic to: 1) Check if err == pgx.ErrNoRows, return 1, 2) If any other error, return error with context, 3) Add test for error propagation.","acceptance_criteria":"- Network errors properly propagated\\n- Permission errors properly propagated\\n- Only pgx.ErrNoRows returns default ID\\n- Error messages include context\\n- Test coverage for error cases","status":"open","priority":1,"issue_type":"bug","created_at":"2025-10-14T23:26:12.235187-07:00","updated_at":"2025-10-14T23:56:05.861783-07:00"}
{"id":"vc-24","title":"Add context deadline checks to long-running PostgreSQL queries","description":"Long-running queries like DetectCycles and GetDependencyTree don't check ctx.Done(). If a client disconnects or times out, these queries continue running as zombies, wasting database resources.","design":"Add context deadline checks in loops that process rows. Use ctx.Err() to detect cancellation. For recursive CTEs, consider setting statement_timeout in PostgreSQL. Add integration tests with cancelled contexts.","acceptance_criteria":"- DetectCycles respects context cancellation\\n- GetDependencyTree respects context cancellation\\n- Zombie queries cleaned up on client disconnect\\n- Tests verify cancellation behavior\\n- No resource leaks on timeout","status":"open","priority":2,"issue_type":"task","created_at":"2025-10-14T23:26:12.235839-07:00","updated_at":"2025-10-14T23:56:05.866715-07:00"}
{"id":"vc-25","title":"Add helper function for scanning issues in PostgreSQL backend","description":"The postgres.go file has duplicated issue scanning logic in SearchIssues, GetDependencies, GetDependents, and other methods. SQLite has a scanIssues() helper that should be replicated for PostgreSQL.","design":"Create scanIssues(rows pgx.Rows) ([]*types.Issue, error) helper function. Handle NULL values for closedAt, estimatedMinutes, assignee consistently. Use in all methods that return []*types.Issue.","acceptance_criteria":"- scanIssues helper function created\\n- All issue-returning methods use helper\\n- NULL handling consistent across methods\\n- Code duplication eliminated\\n- No behavior changes (tests pass)","status":"open","priority":3,"issue_type":"task","created_at":"2025-10-14T23:26:12.236229-07:00","updated_at":"2025-10-14T23:56:05.867298-07:00"}
{"id":"vc-26","title":"Add connection pool metrics and observability to PostgreSQL backend","description":"The PostgreSQL connection pool (pgxpool) provides metrics like active connections, idle connections, wait time, etc. These should be exposed for monitoring and debugging production issues.","design":"Use pgxpool.Stat() to expose metrics. Options: 1) Add GetPoolStats() method to Storage interface, 2) Export metrics to Prometheus, 3) Log periodic stats. Consider adding pool exhaustion warnings.","acceptance_criteria":"- Pool stats exposed via API\\n- Active/idle connection counts available\\n- Wait time/duration tracked\\n- Pool exhaustion warnings logged\\n- Metrics helpful for debugging production issues","status":"open","priority":3,"issue_type":"task","created_at":"2025-10-14T23:26:12.236602-07:00","updated_at":"2025-10-14T23:56:05.871926-07:00"}
{"id":"vc-27","title":"Fix AddLabel/RemoveLabel to check RowsAffected before recording events","description":"AddLabel and RemoveLabel in PostgreSQL backend record events even when no changes occur. AddLabel uses ON CONFLICT DO NOTHING but still records event if label already exists. RemoveLabel records event even if label doesn't exist. This creates misleading audit trail.","design":"Check CommandTag.RowsAffected() after INSERT/DELETE operations. Only record event if rows were actually modified. For AddLabel: result.RowsAffected() \u003e 0. For RemoveLabel: result.RowsAffected() \u003e 0.","acceptance_criteria":"AddLabel skips event when label already exists; RemoveLabel skips event when label doesn't exist; audit trail only shows actual changes","status":"open","priority":1,"issue_type":"bug","created_at":"2025-10-14T23:26:12.236974-07:00","updated_at":"2025-10-14T23:56:05.873959-07:00"}
{"id":"vc-28","title":"Fix DetectCycles N+1 query problem with bulk issue fetch","description":"DetectCycles in PostgreSQL backend has N+1 query problem at postgres.go:792-800. For each issue ID in a cycle path, it calls GetIssue() separately. A cycle with 10 issues makes 10 database round trips. This is inefficient and doesn't scale.","design":"After parsing all cycle paths and collecting unique issue IDs, make single bulk query: SELECT * FROM issues WHERE id IN ($1, $2, ...). Build map[issueID]*Issue for lookup. Then assemble cycles from map. Reduces N queries to 1.","acceptance_criteria":"DetectCycles makes single bulk query for all issues in all cycles; performance scales with unique issues not cycle count","status":"closed","priority":0,"issue_type":"bug","created_at":"2025-10-14T23:26:12.237529-07:00","updated_at":"2025-10-14T23:56:05.876749-07:00"}
{"id":"vc-29","title":"Fix AddDependency race condition by moving validation into transaction","description":"AddDependency validates issue existence at postgres.go:499-513 BEFORE starting transaction at line 523. Race condition: issues could be deleted between validation and insertion, causing foreign key violations or inconsistent state. Also makes 2 extra round trips.","design":"Move GetIssue validation calls inside transaction after Begin(). Or better: remove explicit validation and rely on foreign key constraints - let database enforce referential integrity. Catch and translate FK violation errors to user-friendly messages.","acceptance_criteria":"AddDependency validation happens inside transaction; no race condition possible; foreign key violations handled gracefully","status":"closed","priority":0,"issue_type":"bug","created_at":"2025-10-14T23:26:12.238106-07:00","updated_at":"2025-10-14T23:56:05.881379-07:00"}
{"id":"vc-3","title":"Watchdog and Convergence Detection","description":"Prevents infinite loops, stuck issues, and low-confidence spirals. Monitors executor progress and escalates when tasks aren't making forward progress. Should-have for production reliability.","design":"Monitor executor iterations and detect: 1) Max iterations without issue completion, 2) Repeated low-confidence AI assessments, 3) No progress within time threshold, 4) Escalation count exceeding limit. When detected, escalate to human or abort gracefully.","acceptance_criteria":"- Watchdog monitor component\n- maxIterationsWithoutProgress tracking\n- maxLowConfidenceAssessments tracking\n- minProgressCheckInterval enforcement\n- Escalation thresholds\n- Graceful abort on convergence failure\n- Logging and metrics integration","status":"open","priority":1,"issue_type":"epic","created_at":"2025-10-14T23:26:12.238645-07:00","updated_at":"2025-10-14T23:56:05.88515-07:00","dependencies":[{"issue_id":"vc-3","depends_on_id":"vc-2","type":"blocks","created_at":"2025-10-14T23:26:12.289715-07:00","created_by":"auto-import"}]}
{"id":"vc-30","title":"Add limit validation to GetEvents in PostgreSQL backend","description":"GetEvents at postgres.go:942-945 accepts limit parameter but doesn't validate it. Negative or excessively large limits could cause issues. While integer formatting prevents SQL injection, unbounded queries are a DoS risk.","design":"Add validation: if limit \u003c 0 return error. If limit \u003e 10000 cap at 10000 or return error. Document maximum in function comment.","acceptance_criteria":"GetEvents rejects negative limits; enforces reasonable maximum; documented behavior","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-10-14T23:26:12.239024-07:00","updated_at":"2025-10-14T23:56:05.886758-07:00"}
{"id":"vc-31","title":"Fix GetDependencyTree truncation flag logic","description":"GetDependencyTree at postgres.go:722 sets node.Truncated = node.Depth == maxDepth. This is off-by-one: should be \u003e= maxDepth. Nodes AT maxDepth are the last level returned, so they ARE truncated (their children aren't shown). Current code would only mark imaginary 'maxDepth+1' nodes.","design":"Change line 722 from == to \u003e=. Or better: set truncated=true for nodes whose depth == maxDepth-1 AND they have children in dependencies table. This shows truncation only when children actually exist.","acceptance_criteria":"Truncation flag correct when dependency tree reaches max depth","status":"open","priority":2,"issue_type":"bug","created_at":"2025-10-14T23:26:12.239812-07:00","updated_at":"2025-10-14T23:56:05.902609-07:00"}
{"id":"vc-32","title":"Initialize GetLabels with empty slice instead of nil","description":"GetLabels at postgres.go:874 declares 'var labels []string' which creates nil slice. When no labels exist, returns nil instead of empty slice. Forces callers to check for nil vs empty. Go convention is to return empty slices, not nil.","design":"Change declaration to 'labels := []string{}' at postgres.go:874. Returns consistent empty slice when no labels found.","acceptance_criteria":"GetLabels returns empty slice [] instead of nil when issue has no labels","status":"open","priority":2,"issue_type":"bug","created_at":"2025-10-14T23:26:12.240329-07:00","updated_at":"2025-10-14T23:56:05.921998-07:00"}
{"id":"vc-33","title":"Add rows.Err() checks after iteration in PostgreSQL queries","description":"Multiple query functions in PostgreSQL backend iterate rows but don't check rows.Err() afterward. GetLabels at postgres.go:881 is one example. If iteration stops due to error, we silently return partial results. Should check rows.Err() after loop completes.","design":"After for rows.Next() loops, add: if err := rows.Err(); err \\!= nil { return nil, fmt.Errorf(...) }. Apply to: GetLabels, scanIssues helper, and any other row iteration.","acceptance_criteria":"All row iterations check rows.Err(); partial results never returned silently on error","status":"open","priority":2,"issue_type":"bug","created_at":"2025-10-14T23:26:12.240707-07:00","updated_at":"2025-10-14T23:56:05.925961-07:00"}
{"id":"vc-34","title":"Standardize error wrapping in PostgreSQL backend","description":"Error handling inconsistent across PostgreSQL backend. Some places properly wrap errors with fmt.Errorf and %w, others return raw errors. Example: GetLabels postgres.go:878 returns unwrapped 'err' from Scan. Makes debugging harder - can't trace error origin.","design":"Audit all error returns in postgres.go. Ensure every error is wrapped with context using fmt.Errorf with %w verb. Pattern: return nil, fmt.Errorf('operation failed: %w', err).","acceptance_criteria":"All errors in postgres.go properly wrapped with context; error messages include operation that failed","status":"open","priority":3,"issue_type":"task","created_at":"2025-10-14T23:26:12.241089-07:00","updated_at":"2025-10-14T23:56:05.926605-07:00"}
{"id":"vc-35","title":"Use parameterized LIMIT in GetEvents PostgreSQL query","description":"GetEvents at postgres.go:944 builds LIMIT clause using fmt.Sprintf string concatenation instead of query parameters. While safe (limit is int), this is inconsistent with rest of codebase which uses parameterized queries. Better practice to use placeholders.","design":"Change implementation to use query parameter. If limit \u003e 0, append 'LIMIT $2' to query string and pass limit as second parameter to pool.Query(). Requires adjusting parameter index.","acceptance_criteria":"GetEvents uses parameterized LIMIT clause instead of string concatenation","status":"open","priority":3,"issue_type":"task","created_at":"2025-10-14T23:26:12.241541-07:00","updated_at":"2025-10-14T23:56:05.938092-07:00"}
{"id":"vc-36","title":"Use consistent timestamp source in AddComment","description":"AddComment at postgres.go:930-932 uses NOW() SQL function for updated_at timestamp. This is evaluated at query execution time, not transaction start. Other functions use time.Now() in Go code for consistency. Mixing sources could cause timestamp ordering issues.","design":"Change 'UPDATE issues SET updated_at = NOW()' to 'UPDATE issues SET updated_at = $N' and pass time.Now() as parameter. Captures timestamp at same moment as event creation. Consistent with rest of codebase.","acceptance_criteria":"AddComment uses Go time.Now() instead of SQL NOW(); timestamps consistent across transaction","status":"open","priority":3,"issue_type":"task","created_at":"2025-10-14T23:26:12.242169-07:00","updated_at":"2025-10-14T23:56:05.944528-07:00"}
{"id":"vc-37","title":"Use pgx error codes instead of string matching for FK violations in AddDependency","description":"The AddDependency function in postgres.go currently uses brittle string matching to detect foreign key violations (lines 519-527). It uses strings.Contains() to check error messages, which can break if PostgreSQL changes error message format across versions or locales.\n\nCurrent implementation:\nif strings.Contains(err.Error(), \"foreign key constraint\") || strings.Contains(err.Error(), \"violates foreign key\") {\n    if strings.Contains(err.Error(), \"issue_id\") {\n        return fmt.Errorf(\"issue %s not found\", dep.IssueID)\n    }\n    if strings.Contains(err.Error(), \"depends_on_id\") {\n        return fmt.Errorf(\"dependency target %s not found\", dep.DependsOnID)\n    }\n    return fmt.Errorf(\"one or both issues not found\")\n}\n\nThis approach is fragile and not recommended for production code.","design":"Use pgx's error type system to properly detect and handle foreign key violations:\n\n1. Import github.com/jackc/pgx/v5/pgconn\n2. Use errors.As() to check if error is *pgconn.PgError\n3. Check pgErr.Code == \"23503\" (PostgreSQL FK violation error code)\n4. Use pgErr.ConstraintName to determine which FK was violated\n5. Return appropriate error messages based on constraint name\n\nExample:\nvar pgErr *pgconn.PgError\nif errors.As(err, \u0026pgErr) \u0026\u0026 pgErr.Code == \"23503\" {\n    // FK violation - check which constraint\n    if strings.Contains(pgErr.ConstraintName, \"issue_id\") {\n        return fmt.Errorf(\"issue %s not found\", dep.IssueID)\n    }\n    if strings.Contains(pgErr.ConstraintName, \"depends_on\") {\n        return fmt.Errorf(\"dependency target %s not found\", dep.DependsOnID)\n    }\n    return fmt.Errorf(\"one or both issues not found\")\n}\n\nThis uses PostgreSQL's standard error codes which are stable across versions.","acceptance_criteria":"- Import pgconn package\n- Replace string matching with pgErr.Code == \"23503\" check\n- Use pgErr.ConstraintName instead of matching error message text\n- Code compiles successfully\n- Error handling properly identifies which issue doesn't exist","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-10-14T23:26:12.242844-07:00","updated_at":"2025-10-14T23:56:05.951749-07:00"}
{"id":"vc-38","title":"Add empty ID validation in AddDependency","description":"The AddDependency function in postgres.go does not validate that dep.IssueID and dep.DependsOnID are non-empty before attempting database operations. While the foreign key constraint will catch missing issues, empty strings should be rejected early with a clear error message.\n\nCurrent code only checks for self-dependency:\nif dep.IssueID == dep.DependsOnID {\n    return fmt.Errorf(\"issue cannot depend on itself\")\n}\n\nBut does not check for empty strings, which would fail later with a less clear FK violation error.","design":"Add validation at the start of AddDependency (after self-dependency check):\n\nif dep.IssueID == \"\" || dep.DependsOnID == \"\" {\n    return fmt.Errorf(\"issue IDs cannot be empty\")\n}\n\nThis provides early validation with a clear error message before any database operations are attempted.","acceptance_criteria":"- Add empty string validation for both IssueID and DependsOnID\n- Return clear error message if either is empty\n- Validation occurs before any database operations\n- Code compiles successfully","status":"closed","priority":2,"issue_type":"bug","created_at":"2025-10-14T23:26:12.243283-07:00","updated_at":"2025-10-14T23:56:05.952214-07:00"}
{"id":"vc-39","title":"Add parameter limit protection in DetectCycles bulk query","description":"The DetectCycles function in postgres.go uses a bulk WHERE IN query to fetch all issues involved in cycles (lines 846-863). While this is a huge performance improvement over N+1 queries, it could hit PostgreSQL's parameter limit in pathological cases.\n\nPostgreSQL has a limit of 65535 parameters per query. If there are extremely large cycles or many cycles involving thousands of unique issues, the bulk query could fail.\n\nCurrent code:\nparams := make([]interface{}, len(issueIDList))\nplaceholders := make([]string, len(issueIDList))\nfor i, id := range issueIDList {\n    params[i] = id\n    placeholders[i] = fmt.Sprintf(\"$%d\", i+1)\n}\n\nbulkQuery := fmt.Sprintf(...)\nissueRows, err := s.pool.Query(ctx, bulkQuery, params...)\n\nThis could theoretically exceed parameter limits in extreme cases.","design":"Add batching logic to handle large numbers of issue IDs:\n\n1. Define a reasonable batch size (e.g., 1000 issues per query)\n2. If len(issueIDList) \u003c= batchSize, use current single-query approach\n3. If len(issueIDList) \u003e batchSize, split into batches:\n   - Process batches of up to 1000 IDs each\n   - Merge results into the issueMap\n4. Continue with existing cycle assembly logic\n\nExample:\nconst maxBatchSize = 1000\nissueMap := make(map[string]*types.Issue)\n\nfor i := 0; i \u003c len(issueIDList); i += maxBatchSize {\n    end := i + maxBatchSize\n    if end \u003e len(issueIDList) {\n        end = len(issueIDList)\n    }\n    batch := issueIDList[i:end]\n    \n    // Build and execute query for this batch\n    // Merge results into issueMap\n}\n\nThis ensures we never exceed PostgreSQL's parameter limits.","acceptance_criteria":"- Add batch size constant (1000 issues)\n- Implement batching logic when issue count exceeds limit\n- Single query optimization still used for small result sets\n- All issues fetched and merged correctly\n- Code compiles successfully","status":"open","priority":2,"issue_type":"bug","created_at":"2025-10-14T23:26:12.24365-07:00","updated_at":"2025-10-14T23:56:05.959599-07:00"}
{"id":"vc-4","title":"Git Operations Integration","description":"Complete the loop from code changes to mergeable PR. Enables branch creation, commits with proper messages, and PR preparation. Should-have for true 'Engineer-in-a-Box' functionality.","design":"After quality gates pass, automatically: 1) Create feature branch (if not exists), 2) Stage and commit changes with descriptive message, 3) Push to remote, 4) Optionally create PR or prepare for human review. Integrate with issue closer to link commits to issues.","acceptance_criteria":"- Git branch creation/detection\n- Automatic staging of changes\n- Commit message generation (linked to issues)\n- Push to remote support\n- PR creation (via gh CLI or manual prep)\n- Integration with issue workflow\n- Rollback/cleanup on failures","status":"open","priority":1,"issue_type":"epic","created_at":"2025-10-14T23:26:12.24403-07:00","updated_at":"2025-10-14T23:56:05.960101-07:00","dependencies":[{"issue_id":"vc-4","depends_on_id":"vc-2","type":"blocks","created_at":"2025-10-14T23:26:12.290199-07:00","created_by":"auto-import"}]}
{"id":"vc-40","title":"Handle missing issues gracefully in DetectCycles","description":"The DetectCycles function in postgres.go silently skips issues that are in the cycle path but cannot be fetched from the database (lines 870-874). This could hide data integrity issues.\n\nCurrent code:\nfor _, issueID := range cp.issueIDs {\n    issue, ok := issueMap[issueID]\n    if !ok {\n        continue  // Silently skip missing issues\n    }\n    cycleIssues = append(cycleIssues, issue)\n}\n\nIf an issue appears in a dependency cycle but doesn't exist in the issues table, this is a data integrity problem that should be logged or reported, not silently ignored.","design":"Add logging or error reporting for missing issues in cycles:\n\nOption 1 (Logging):\nfor _, issueID := range cp.issueIDs {\n    issue, ok := issueMap[issueID]\n    if !ok {\n        // Log data integrity issue\n        s.logger.Warn(\"issue in cycle path not found in database\", \"issue_id\", issueID, \"path\", cp.path)\n        continue\n    }\n    cycleIssues = append(cycleIssues, issue)\n}\n\nOption 2 (Error return):\nReturn an error if any issue in a cycle path is missing, indicating data corruption.\n\nRecommendation: Option 1 (logging) is better - we still want to detect and report other cycles even if one has data integrity issues.","acceptance_criteria":"- Add logging for missing issues in cycle paths\n- Log includes issue ID and full cycle path for debugging\n- Function continues processing other cycles\n- Does not break existing functionality\n- Code compiles successfully","status":"open","priority":3,"issue_type":"bug","created_at":"2025-10-14T23:26:12.244402-07:00","updated_at":"2025-10-14T23:56:05.972123-07:00"}
{"id":"vc-41","title":"Use deterministic ordering in DetectCycles for consistent results","description":"The DetectCycles function in postgres.go builds issueIDList from a map using range iteration (lines 836-839), which has non-deterministic order in Go:\n\nissueIDList := make([]string, 0, len(uniqueIssueIDs))\nfor id := range uniqueIssueIDs {\n    issueIDList = append(issueIDList, id)\n}\n\nWhile this doesn't affect correctness, it means the SQL query parameters and results can appear in different orders across runs, making debugging harder and test results non-deterministic.","design":"Sort the issue ID list before building the query:\n\nissueIDList := make([]string, 0, len(uniqueIssueIDs))\nfor id := range uniqueIssueIDs {\n    issueIDList = append(issueIDList, id)\n}\nsort.Strings(issueIDList)  // Add deterministic ordering\n\nThis ensures:\n1. SQL queries are consistent across runs\n2. Test results are deterministic\n3. Debugging is easier (logs show same order)\n4. No performance impact (sorting small lists is fast)\n\nNote: The cycles themselves are already ordered by the SQL query's ORDER BY clause, so this only affects the intermediate issue fetching.","acceptance_criteria":"- Import sort package\n- Sort issueIDList after building from map\n- SQL queries use consistent parameter order\n- Tests produce deterministic results\n- Code compiles successfully","status":"open","priority":3,"issue_type":"bug","created_at":"2025-10-14T23:26:12.245013-07:00","updated_at":"2025-10-14T23:56:05.976899-07:00"}
{"id":"vc-42","title":"Empty Backend string should default to sqlite in NewStorage","description":"In storage.go NewStorage() function, when cfg.Backend is an empty string, the switch statement falls through to the default case and returns an error: 'unsupported backend:  (must be 'sqlite' or 'postgres')'.\n\nThis is inconsistent with DefaultConfig() which sets Backend='sqlite' as the default. Users might pass a Config with Backend=\"\" expecting it to use the default.\n\nCurrent behavior at lines 111-173:\nswitch cfg.Backend {\ncase \"sqlite\": ...\ncase \"postgres\": ...\ndefault:\n    return nil, fmt.Errorf(\"unsupported backend: %s...\", cfg.Backend)\n}\n\nWhen Backend=\"\", this returns an error instead of defaulting to sqlite.","design":"Add explicit handling for empty Backend string before the switch statement:\n\nif cfg.Backend == \"\" {\n    cfg.Backend = \"sqlite\"\n}\n\nswitch cfg.Backend {\ncase \"sqlite\": ...\ncase \"postgres\": ...\ndefault: ...\n}\n\nThis matches the behavior of DefaultConfig() which uses sqlite as the default backend.","acceptance_criteria":"- Empty Backend string defaults to \"sqlite\"\n- Error message still shown for invalid backend names\n- DefaultConfig() and NewStorage() have consistent default behavior\n- Code compiles successfully","status":"open","priority":2,"issue_type":"bug","created_at":"2025-10-14T23:26:12.245576-07:00","updated_at":"2025-10-14T23:56:06.003261-07:00"}
{"id":"vc-43","title":"Remove duplicate default logic in NewStorage postgres path","description":"In storage.go NewStorage() function, PostgreSQL connection pool defaults are duplicated in two places:\n\n1. storage.DefaultConfig() sets defaults at lines 87-101\n2. NewStorage() re-applies defaults at lines 149-167\n\nThis creates maintenance burden - if postgres.DefaultConfig() changes, NewStorage() must also be updated. The defaults could drift out of sync.\n\nCurrent code:\n// Build postgres config\npgCfg := \u0026postgres.Config{\n    Host: cfg.Host,\n    MaxConns: cfg.MaxConns,  // Might be 0\n    ...\n}\n\n// Apply defaults if not set\nif pgCfg.MaxConns == 0 {\n    pgCfg.MaxConns = 25  // Hardcoded duplicate\n}\n\nThis duplicates the default value of 25 that's already in postgres.DefaultConfig().","design":"Use postgres.DefaultConfig() as the base and merge user-provided values:\n\n// Start with postgres defaults\npgCfg := postgres.DefaultConfig()\n\n// Override with user-provided values\npgCfg.Host = cfg.Host\npgCfg.Port = cfg.Port\npgCfg.Database = cfg.Database\npgCfg.User = cfg.User\npgCfg.Password = cfg.Password\n\n// Only override pool settings if explicitly set (non-zero)\nif cfg.SSLMode != \"\" {\n    pgCfg.SSLMode = cfg.SSLMode\n}\nif cfg.MaxConns != 0 {\n    pgCfg.MaxConns = cfg.MaxConns\n}\n// ... etc\n\nThis ensures postgres.DefaultConfig() is the single source of truth for defaults.","acceptance_criteria":"- Remove duplicate default values from NewStorage()\n- Use postgres.DefaultConfig() as base for building pgCfg\n- User-provided values override defaults\n- Defaults only exist in one place (postgres.DefaultConfig)\n- Code compiles successfully","status":"open","priority":2,"issue_type":"bug","created_at":"2025-10-14T23:26:12.246195-07:00","updated_at":"2025-10-14T23:56:06.003702-07:00"}
{"id":"vc-44","title":"Document SQLite/PostgreSQL context parameter inconsistency","description":"The SQLite and PostgreSQL backend constructors have inconsistent signatures:\n\n- sqlite.New(path string) (*SQLiteStorage, error)  // No context\n- postgres.New(ctx context.Context, cfg *Config) (*PostgresStorage, error)  // Takes context\n\nThis inconsistency is visible in NewStorage() at lines 117 vs 169:\nreturn sqlite.New(cfg.Path)      // No context passed\nreturn postgres.New(ctx, pgCfg)  // Context passed\n\nThis is existing technical debt in the backend implementations, not something created by vc-21. However, it should be documented as a known issue.\n\nImpact:\n- Inconsistent API design between backends\n- SQLite can't respect context cancellation during initialization\n- Makes it harder to swap backends (different function signatures)","design":"Add a comment in storage.go documenting this inconsistency:\n\n// NewStorage creates a new storage backend based on configuration\n// Note: SQLite backend does not accept a context parameter, only PostgreSQL does.\n// This is a known API inconsistency between the backends.\nfunc NewStorage(ctx context.Context, cfg *Config) (Storage, error) {\n    ...\n}\n\nOptionally create a follow-up issue to fix the backend implementations:\n- Update sqlite.New() to accept context\n- Use context for initialization operations\n- Make both backends consistent","acceptance_criteria":"- Comment added documenting the context parameter inconsistency\n- Explains why sqlite.New() doesn't receive ctx\n- Optional: Create follow-up issue to fix sqlite.New() signature","status":"open","priority":2,"issue_type":"task","created_at":"2025-10-14T23:26:12.246658-07:00","updated_at":"2025-10-14T23:56:06.004129-07:00"}
{"id":"vc-45","title":"DefaultConfig should only populate fields for selected backend","description":"In storage.go, DefaultConfig() populates fields for both SQLite and PostgreSQL backends, even though only one will be used:\n\nreturn \u0026Config{\n    Backend:         \"sqlite\",\n    Path:            \".beads/vc.db\",\n    Host:            \"localhost\",    // PostgreSQL fields\n    Port:            5432,\n    Database:        \"vc\",\n    User:            \"vc\",\n    MaxConns:        25,\n    // ... etc\n}\n\nWhen Backend=\"sqlite\", the PostgreSQL fields (Host, Port, Database, User, MaxConns, etc.) are unused but still allocated.\n\nIssues:\n- Wastes memory for unused fields\n- Confusing: why does a SQLite config have \"User\" and \"Port\" set?\n- Makes config serialization/display messy (shows irrelevant fields)\n\nThis is a minor issue but reduces clarity.","design":"Option 1 (simpler): Keep current behavior, add documentation\n- Document that Config contains fields for all backends\n- Note that only relevant fields are used based on Backend value\n\nOption 2 (cleaner): Make backend-specific defaults\n- Create DefaultSQLiteConfig() and DefaultPostgresConfig() functions\n- DefaultConfig() just returns DefaultSQLiteConfig()\n- Users can call the specific one they need\n\nRecommendation: Option 1 for now (just document), Option 2 if we add more backends.","acceptance_criteria":"- Add comment explaining Config contains fields for all backends\n- Document that irrelevant fields are ignored based on Backend value\n- Optional: Consider backend-specific config functions for future","status":"open","priority":3,"issue_type":"task","created_at":"2025-10-14T23:26:12.247088-07:00","updated_at":"2025-10-14T23:56:06.004572-07:00"}
{"id":"vc-46","title":"Add validation that Backend matches populated config fields","description":"In storage.go, there's no validation that the Backend field matches the populated configuration fields. This allows invalid configurations:\n\nExample 1: Backend=\"sqlite\" but PostgreSQL fields populated\ncfg := \u0026Config{\n    Backend: \"sqlite\",\n    Path: \".beads/vc.db\",\n    Host: \"localhost\",  // Irrelevant for SQLite\n    Port: 5432,\n    Database: \"vc\",\n}\n\nExample 2: Backend=\"postgres\" but Path populated\ncfg := \u0026Config{\n    Backend: \"postgres\",\n    Path: \".beads/vc.db\",  // Irrelevant for PostgreSQL\n    Host: \"localhost\",\n    Port: 5432,\n}\n\nNewStorage() will work but silently ignore the wrong fields. This makes debugging configuration issues harder - users won't know why their Host setting isn't working when they meant to use postgres but accidentally set Backend=\"sqlite\".","design":"Add validation in NewStorage() before the switch statement:\n\n// Validate config consistency\nif cfg.Backend == \"sqlite\" {\n    if cfg.Host \\!= \"\" || cfg.Port \\!= 0 {\n        // Option 1: Warning (log)\n        log.Warn(\"PostgreSQL fields set but Backend is sqlite, ignoring\")\n        \n        // Option 2: Error (strict)\n        return nil, fmt.Errorf(\"Backend is sqlite but PostgreSQL fields are set\")\n    }\n}\n\nRecommendation: Option 1 (warning) for now, since Config is a flat struct. If we add more backends, consider splitting into backend-specific config types.","acceptance_criteria":"- Add validation checking Backend matches populated fields\n- Either log warning or return error for mismatches\n- Document which fields are relevant for which backend\n- Code compiles successfully","status":"open","priority":3,"issue_type":"task","created_at":"2025-10-14T23:26:12.24754-07:00","updated_at":"2025-10-14T23:56:06.005067-07:00"}
{"id":"vc-47","title":"Normalize Backend string to lowercase before comparison in NewStorage","description":"In storage.go NewStorage() function, the Backend field is compared case-sensitively:\n\nswitch cfg.Backend {\ncase \"sqlite\":\n    ...\ncase \"postgres\":\n    ...\n}\n\nThis means \"SQLite\", \"SQLITE\", \"Postgres\", \"PostgreSQL\", etc. would all fail with 'unsupported backend' error.\n\nWhile the documentation says Backend should be \"sqlite\" or \"postgres\", users might naturally type \"SQLite\" or \"PostgreSQL\". Case-insensitive matching would be more user-friendly.\n\nCurrent behavior:\n- \"sqlite\" ✓ works\n- \"SQLite\" ✗ error\n- \"postgres\" ✓ works  \n- \"PostgreSQL\" ✗ error\n\nExpected behavior: All should work.","design":"Normalize Backend to lowercase before the switch:\n\nfunc NewStorage(ctx context.Context, cfg *Config) (Storage, error) {\n    if cfg == nil {\n        cfg = DefaultConfig()\n    }\n    \n    // Normalize backend name to lowercase\n    backend := strings.ToLower(cfg.Backend)\n    \n    // Validate backend type\n    switch backend {\n    case \"sqlite\":\n        ...\n    case \"postgres\":\n        ...\n    default:\n        return nil, fmt.Errorf(\"unsupported backend: %s (must be 'sqlite' or 'postgres')\", cfg.Backend)\n    }\n}\n\nNote: Keep original cfg.Backend in error message so user sees what they actually typed.","acceptance_criteria":"- Add strings.ToLower() before switch statement\n- All case variations of sqlite/postgres work\n- Error message shows original (non-normalized) Backend value\n- Code compiles successfully","status":"open","priority":3,"issue_type":"task","created_at":"2025-10-14T23:26:12.247958-07:00","updated_at":"2025-10-14T23:56:06.005686-07:00"}
{"id":"vc-48","title":"Fix race condition in UpdateExecutionState using atomic UPDATE","description":"UpdateExecutionState in postgres/execution_state.go:129-147 has a race condition. It reads current state with GetExecutionState, validates transition, then updates. Between read and update, another transaction could modify the state.\n\nCurrent flow:\n1. GetExecutionState (read)\n2. Validate transition\n3. UPDATE (write)\n\nThis is a check-then-act race condition.","design":"Replace the read-validate-update pattern with a single atomic UPDATE that includes the validation:\n\n```go\nquery := `\n    UPDATE issue_execution_state\n    SET state = $1, updated_at = $2\n    WHERE issue_id = $3 AND state = $4\n`\nresult, err := s.pool.Exec(ctx, query, newState, time.Now(), issueID, expectedCurrentState)\nif result.RowsAffected() == 0 {\n    // Either issue not found OR state changed (concurrent modification)\n    // Need to distinguish these cases\n}\n```\n\nAlternative: Use SELECT FOR UPDATE in a transaction to lock the row.","acceptance_criteria":"- UpdateExecutionState prevents concurrent state modifications\n- Invalid transitions still return appropriate errors\n- No performance regression\n- Tests verify concurrent update behavior","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-10-14T23:26:12.248475-07:00","updated_at":"2025-10-14T23:56:06.006367-07:00"}
{"id":"vc-49","title":"Remove redundant claim check in ClaimIssue","description":"ClaimIssue in postgres/execution_state.go:25-33 performs a redundant SELECT to check if issue is already claimed before the INSERT. The INSERT itself will fail with a unique constraint violation (error 23505) if the issue is already claimed, which we already handle at lines 66-70.\n\nThe redundant check adds an extra database roundtrip without providing additional safety.","design":"Remove lines 25-33:\n```go\n// Check if issue is already claimed\nvar existingExecutor string\nerr = tx.QueryRow(ctx, \"SELECT executor_instance_id FROM issue_execution_state WHERE issue_id = $1\", issueID).Scan(\u0026existingExecutor)\nif err != nil \u0026\u0026 err != pgx.ErrNoRows {\n    return fmt.Errorf(\"failed to check execution state: %w\", err)\n}\nif err == nil {\n    return fmt.Errorf(\"issue %s is already claimed by another executor\", issueID)\n}\n```\n\nThe existing constraint check at lines 66-70 is sufficient and atomic.","acceptance_criteria":"- ClaimIssue still prevents double-claiming\n- One fewer database roundtrip per claim\n- All existing tests still pass\n- Error message for already-claimed issues remains clear","status":"closed","priority":2,"issue_type":"task","created_at":"2025-10-14T23:26:12.248883-07:00","updated_at":"2025-10-14T23:56:06.006857-07:00"}
{"id":"vc-5","title":"Beads Integration and Executor Tables","description":"Foundation work: Extend Beads with VC-specific fields and executor tables. This is the base layer that all other phases depend on.","design":"Add: 1) discovered-from dependency type (already in Beads), 2) design/acceptance_criteria/notes fields (already in Beads), 3) executor_instances table for tracking worker instances, 4) issue_execution_state table for checkpointing/resumption, 5) Ensure PostgreSQL backend works alongside SQLite","acceptance_criteria":"- discovered-from dependency type verified working\n- design, acceptance_criteria, notes fields verified working\n- executor_instances table created and schema documented\n- issue_execution_state table created with checkpoint support\n- PostgreSQL backend tested (while keeping SQLite as default)\n- Migration/initialization scripts created\n- All beads tests passing with new tables","notes":"Progress: 2 of 6 child tasks completed (vc-10, vc-11). executor_instances table fully implemented with type-safe enum and validation. Next: vc-12 (issue_execution_state table).","status":"open","priority":0,"issue_type":"epic","created_at":"2025-10-14T23:26:12.249298-07:00","updated_at":"2025-10-14T23:56:06.007366-07:00","dependencies":[{"issue_id":"vc-5","depends_on_id":"vc-10","type":"parent-child","created_at":"2025-10-14T23:26:12.290707-07:00","created_by":"auto-import"},{"issue_id":"vc-5","depends_on_id":"vc-11","type":"parent-child","created_at":"2025-10-14T23:26:12.291115-07:00","created_by":"auto-import"},{"issue_id":"vc-5","depends_on_id":"vc-12","type":"parent-child","created_at":"2025-10-14T23:26:12.291528-07:00","created_by":"auto-import"},{"issue_id":"vc-5","depends_on_id":"vc-13","type":"parent-child","created_at":"2025-10-14T23:26:12.29192-07:00","created_by":"auto-import"},{"issue_id":"vc-5","depends_on_id":"vc-14","type":"parent-child","created_at":"2025-10-14T23:26:12.292309-07:00","created_by":"auto-import"},{"issue_id":"vc-5","depends_on_id":"vc-15","type":"parent-child","created_at":"2025-10-14T23:26:12.292714-07:00","created_by":"auto-import"}]}
{"id":"vc-50","title":"Make GROUP BY explicit in GetBlockedIssues","description":"GetBlockedIssues in postgres/ready.go:93 uses 'GROUP BY i.id' which works because i.id is a primary key, but some PostgreSQL configurations require all non-aggregated SELECT columns to be explicitly listed in GROUP BY.\n\nThe schema view (schema.go:92-94) does this correctly by listing all columns.","design":"Replace:\n```go\nGROUP BY i.id\n```\n\nWith:\n```go\nGROUP BY i.id, i.title, i.description, i.design, i.acceptance_criteria, i.notes,\n         i.status, i.priority, i.issue_type, i.assignee, i.estimated_minutes,\n         i.created_at, i.updated_at, i.closed_at\n```\n\nThis matches the pattern used in the blocked_issues view in schema.go.","acceptance_criteria":"- Query works on all PostgreSQL configurations\n- No change in query results\n- Matches schema view pattern\n- All tests pass","status":"closed","priority":2,"issue_type":"task","created_at":"2025-10-14T23:26:12.249706-07:00","updated_at":"2025-10-14T23:56:06.007879-07:00"}
{"id":"vc-51","title":"Add PostgreSQL integration tests for execution state operations","description":"The PostgreSQL backend execution state and ready work operations lack integration tests. Currently we only have SQLite tests. This creates a gap in test coverage for PostgreSQL-specific behavior:\n\n- JSONB checkpoint data handling\n- array_agg in GetBlockedIssues\n- PostgreSQL-specific error codes (23505)\n- COUNT(*) FILTER syntax\n- EXTRACT(EPOCH) for timestamps\n\nThe SQLite tests verify the business logic, but not the PostgreSQL-specific implementation details.","design":"Create postgres/execution_state_test.go and postgres/ready_test.go that:\n\n1. Use testcontainers or similar to spin up PostgreSQL\n2. Port key tests from sqlite/execution_state_test.go\n3. Add PostgreSQL-specific tests:\n   - JSONB marshaling/unmarshaling edge cases\n   - array_agg with various data\n   - Concurrent ClaimIssue attempts (race testing)\n   - Verify error codes match expectations\n\nFollow the pattern in sqlite tests but adapt for PostgreSQL connection handling.","acceptance_criteria":"- PostgreSQL-specific tests exist and pass\n- Tests cover JSONB, array_agg, error codes\n- Tests use real PostgreSQL (not mocks)\n- CI can run tests (either with testcontainers or postgres service)\n- Test coverage metrics show adequate coverage","status":"open","priority":3,"issue_type":"task","created_at":"2025-10-14T23:26:12.250091-07:00","updated_at":"2025-10-14T23:56:06.008383-07:00"}
{"id":"vc-52","title":"Add defensive handling for array_agg null in GetBlockedIssues","description":"GetBlockedIssues in postgres/ready.go:86 uses array_agg(d.depends_on_id) which could theoretically return {NULL} in edge cases. While the JOINs should prevent this, defensive programming suggests handling it.\n\nCurrently we scan directly into []string at line 107. If array_agg somehow returns {NULL}, we'd get a slice with one empty/null element.","design":"Add validation after scanning blockerIDs:\n\n```go\nissue.BlockedBy = blockerIDs\n\n// Filter out any null/empty blocker IDs (defensive)\nif len(blockerIDs) == 1 \u0026\u0026 blockerIDs[0] == \"\" {\n    issue.BlockedBy = []string{}\n}\n```\n\nOr use COALESCE in the query:\n```sql\nCOALESCE(array_agg(d.depends_on_id), ARRAY[]::text[]) as blocker_ids\n```\n\nThe query approach is cleaner.","acceptance_criteria":"- GetBlockedIssues handles edge cases gracefully\n- No null/empty strings in BlockedBy arrays\n- Existing behavior unchanged for normal cases\n- Add test case for edge condition if possible","status":"open","priority":3,"issue_type":"task","created_at":"2025-10-14T23:26:12.250512-07:00","updated_at":"2025-10-14T23:56:06.008833-07:00"}
{"id":"vc-53","title":"Fix double ReleaseIssue call in executor","description":"Bug: executeIssue() was calling ReleaseIssue() twice - once in the error path (via releaseIssueWithError) and again unconditionally at the end. This caused 'execution state not found' errors.\n\nFix: Moved ReleaseIssue() call inside the success branch only, since releaseIssueWithError() already handles the error path.","acceptance_criteria":"\n- ReleaseIssue only called once per execution\n- No 'execution state not found' errors\n- Error path properly releases via releaseIssueWithError\n- Success path properly releases before return\n","status":"closed","priority":2,"issue_type":"bug","created_at":"2025-10-14T23:26:12.25084-07:00","updated_at":"2025-10-14T23:56:06.009266-07:00"}
{"id":"vc-54","title":"Fix race condition in agent output capture","description":"The agent output capture goroutines have a race condition where console printing happens outside the mutex lock.\n\nLocation: internal/executor/agent.go:207-208 and 229-230\n\nIssue:\n- Line 207: fmt.Println(line) happens outside mutex\n- Line 229: fmt.Fprintln(os.Stderr, line) happens outside mutex\n- The mutex-protected append and the console print can interleave\n\nThis could cause output to appear out of order on the console vs. what's captured in memory.","design":"Move the console printing inside the mutex:\n\n// Capture stdout\ngo func() {\n    defer wg.Done()\n    scanner := bufio.NewScanner(a.stdout)\n    for scanner.Scan() {\n        line := scanner.Text()\n        a.mu.Lock()\n        \n        if len(a.result.Output) \u003c maxOutputLines {\n            a.result.Output = append(a.result.Output, line)\n            // Print inside mutex to ensure ordering\n            fmt.Println(line)\n        } else if len(a.result.Output) == maxOutputLines {\n            a.result.Output = append(a.result.Output, \"[... truncated ...]\")\n        }\n        \n        a.mu.Unlock()\n    }\n}()\n\nSame pattern for stderr capture.","acceptance_criteria":"\n- Console output order matches captured output order\n- No race conditions detected by go test -race\n- Output capture still works correctly\n","status":"closed","priority":2,"issue_type":"bug","created_at":"2025-10-14T23:26:12.251237-07:00","updated_at":"2025-10-14T23:56:06.009692-07:00"}
{"id":"vc-55","title":"Improve agent process cleanup and verification","description":"When agent execution times out, we call Kill() but don't verify the process actually died.\n\nLocation: internal/executor/agent.go:140\n\nIssue:\n- Kill() may fail silently\n- Process could become a zombie\n- No verification that kill succeeded\n\nThis could lead to orphaned processes accumulating over time.","design":"After calling Kill(), wait briefly and verify the process is dead:\n\na.Kill()\n// Give process time to die\ntime.Sleep(100 * time.Millisecond)\nif a.cmd.Process != nil {\n    // Check if process still exists\n    if err := a.cmd.Process.Signal(syscall.Signal(0)); err == nil {\n        // Process still alive - escalate to SIGKILL on Unix\n        a.cmd.Process.Signal(syscall.SIGKILL)\n    }\n}\n\nPlatform-specific considerations:\n- Unix: Can use SIGKILL if SIGTERM fails\n- Windows: Process.Kill() is already forceful\n\nConsider adding a ProcessManager to track spawned agents for cleanup on executor shutdown.","acceptance_criteria":"\n- Kill() failures are detected and logged\n- Zombie processes are prevented\n- Process cleanup verified before returning\n- Consider adding agent process registry\n","status":"open","priority":3,"issue_type":"task","created_at":"2025-10-14T23:26:12.251651-07:00","updated_at":"2025-10-14T23:56:06.01017-07:00"}
{"id":"vc-56","title":"Add logging for claim race conditions","description":"When ClaimIssue fails due to race condition (another executor claimed it first), we silently return nil. This makes it hard to debug multi-executor scenarios.\n\nLocation: internal/executor/executor.go:218-221\n\nCurrent behavior:\nif err := e.store.ClaimIssue(ctx, issue.ID, e.instanceID); err != nil {\n    return nil  // Silent ignore\n}\n\nThis is correct behavior (race conditions are expected), but we should log for observability.","design":"Add debug-level logging when claim fails:\n\nif err := e.store.ClaimIssue(ctx, issue.ID, e.instanceID); err != nil {\n    fmt.Fprintf(os.Stderr, \"debug: issue %s already claimed: %v\\n\", issue.ID, err)\n    return nil\n}\n\nLater, when adding structured logging:\n- Use debug level (not error)\n- Include issue ID and executor instance ID\n- Track claim race metrics","acceptance_criteria":"\n- Claim failures logged at debug level\n- Log includes issue ID and reason\n- Does not spam logs under normal operation\n- Helps debug multi-executor scenarios\n","status":"open","priority":3,"issue_type":"task","created_at":"2025-10-14T23:26:12.252116-07:00","updated_at":"2025-10-14T23:56:06.010695-07:00"}
{"id":"vc-57","title":"Add execution state transitions to executor workflow","description":"Currently executor only sets execution state to 'executing' once. Need to update state as issue progresses through phases: claimed -\u003e assessing -\u003e executing -\u003e analyzing -\u003e gates -\u003e completed. This makes debugging much easier - you can see exactly where an issue is stuck.","design":"Update executeIssue() in internal/executor/executor.go to call UpdateExecutionState() at each phase transition:\n- Before AI assessment: ExecutionStateAssessing\n- Before spawning agent: ExecutionStateExecuting  \n- After agent completes: ExecutionStateAnalyzing\n- After AI analysis (if quality gates enabled): ExecutionStateGates\n- After successful completion: ExecutionStateCompleted\n\nAlso update error paths to set appropriate states.","acceptance_criteria":"- State transitions logged at each phase\n- Can query database to see which phase an issue is in\n- Error handling preserves state information","notes":"Implementation complete:\n- Added ExecutionStateAssessing before AI assessment (line 256)\n- Added ExecutionStateExecuting before spawning agent (line 287)  \n- Added ExecutionStateAnalyzing after agent completes, before AI analysis (line 316)\n- Added ExecutionStateCompleted on successful completion (line 398)\n\nState transition flow:\n- With AI supervision: assessing -\u003e executing -\u003e analyzing -\u003e completed\n- Without AI supervision: executing -\u003e completed\n\nExecutionStateGates will be used when vc-8 (Quality Gates) is implemented.\n\nAll state updates use warning-level logging on failure so they don't break execution.","status":"closed","priority":0,"issue_type":"task","created_at":"2025-10-14T23:26:12.252821-07:00","updated_at":"2025-10-14T23:56:06.011452-07:00"}
{"id":"vc-58","title":"Add resilient JSON parser for AI responses","description":"AI responses sometimes include markdown code fences, explanatory text, or other non-JSON content. Current json.Unmarshal() fails hard on malformed responses. Port the resilient JSON parser from vibecoder (src/utils/json-parser.ts, safe-json-parser.ts) to handle common AI response patterns.","design":"Create internal/ai/json_parser.go with:\n- Strip markdown code fences (backticks)\n- Extract JSON from mixed text responses\n- Handle common AI quirks (trailing commas, comments, etc.)\n- Fallback strategies for partial JSON\n- Log warnings but don't fail on parse errors\n\nReference vibecoder implementation at:\n- src/utils/json-parser-unified.ts\n- src/utils/safe-json-parser.ts\n- test/utils/resilient-json-parser.test.ts","acceptance_criteria":"- Can parse JSON from markdown code blocks\n- Handles common AI response variations\n- Comprehensive test suite\n- Logs parse warnings without failing","status":"closed","priority":1,"issue_type":"task","created_at":"2025-10-14T23:26:12.253471-07:00","updated_at":"2025-10-14T23:56:06.012028-07:00"}
{"id":"vc-59","title":"Add timeout and retry logic for AI API calls","description":"AI API calls can hang or fail due to transient network issues. Need timeout context and retry logic with exponential backoff. Vibecoder had robust retry through Temporal - we need lightweight Go equivalent.","design":"In internal/ai/supervisor.go:\n1. Add context timeout (60s) to API calls\n2. Implement retry with exponential backoff:\n   - Max 3 retries\n   - Backoff: 1s, 2s, 4s\n   - Only retry on transient errors (network, 5xx, rate limits)\n   - Don't retry on 4xx client errors\n3. Add circuit breaker pattern to prevent cascading failures\n4. Make retry config tunable\n\nReference vibecoder patterns in:\n- src/executor/issue-workflow-executor.ts\n- Temporal retry policies (though we're not using Temporal)","acceptance_criteria":"- API calls timeout after 60s\n- Transient failures automatically retried\n- Circuit breaker prevents cascading failures\n- Retry metrics logged","notes":"Implemented timeout and retry logic with exponential backoff (1s, 2s, 4s). API calls now timeout after 60s. Transient errors (5xx, timeouts, network errors, rate limits) are automatically retried. Retry metrics are logged.\n\nStill TODO: Circuit breaker pattern (follow-up issue created). Current implementation provides substantial resilience - retries handle transient failures, non-retriable errors (4xx) fail fast.\n\nChanges in internal/ai/supervisor.go:\n- Added RetryConfig struct with tunable parameters\n- Added retryWithBackoff() with exponential backoff\n- Added isRetriableError() to classify errors\n- Wrapped both API calls with retry logic\n\nTests passing. Ready for review.","status":"open","priority":1,"issue_type":"task","created_at":"2025-10-14T23:26:12.254081-07:00","updated_at":"2025-10-14T23:56:06.012443-07:00"}
{"id":"vc-6","title":"Issue Processor Event Loop","description":"Build the event loop that claims and executes issues via coding agents. No AI supervision yet - just mechanical claiming, spawning agents, and updating status. The core execution engine.","design":"Port IssueWorkflowExecutor pattern: 1) Atomic claiming with PostgreSQL FOR UPDATE SKIP LOCKED, 2) Spawn Cody/Claude Code with -stream-json, 3) Parse agent output and update issue status, 4) Handle epic completion detection, 5) Support pause/resume/abort. Pure orchestration layer with no AI decision-making yet.","acceptance_criteria":"- Event loop running continuously\n- Atomic issue claiming from ready work queue\n- Cody/Claude Code spawning and lifecycle management\n- Agent output parsing and status updates\n- Epic completion detection (all children closed)\n- Pause/resume/abort commands working\n- Basic error handling and retries\n- 'vc execute' command working end-to-end","status":"open","priority":0,"issue_type":"epic","created_at":"2025-10-14T23:26:12.254696-07:00","updated_at":"2025-10-14T23:56:06.012853-07:00","dependencies":[{"issue_id":"vc-6","depends_on_id":"vc-5","type":"blocks","created_at":"2025-10-14T23:26:12.293127-07:00","created_by":"auto-import"}]}
{"id":"vc-60","title":"Add integration tests for AI supervision","description":"AI supervision code (vc-7) has no tests. Need comprehensive test coverage for assessment, analysis, discovered issue creation, and error handling.","design":"Create internal/ai/supervisor_test.go with:\n1. Mock Anthropic client for deterministic testing\n2. Unit tests:\n   - Assessment prompt building\n   - Analysis prompt building\n   - JSON parsing (happy path + errors)\n   - Priority/type mapping\n   - Discovered issue creation\n3. Integration tests:\n   - Full assessment -\u003e execution -\u003e analysis flow\n   - Fallback behavior when AI fails\n   - Partial failure scenarios (some issues created, then error)\n4. Table-driven tests for edge cases\n\nAlso create internal/executor/executor_test.go for executor AI integration tests.","acceptance_criteria":"- \u003e80% code coverage for internal/ai package\n- Mock client for repeatable tests\n- Tests for error paths and edge cases\n- CI pipeline runs tests automatically","notes":"Test implementation complete:\n\n**What's tested (100% coverage):**\n- buildAssessmentPrompt() - Verified all issue fields included\n- buildAnalysisPrompt() - Tested success/failure scenarios\n- truncateString() - All edge cases covered\n- CreateDiscoveredIssues() - 96.2% coverage:\n  - Single and multiple issue creation\n  - All type mappings (bug/task/feature/chore/epic)\n  - All priority mappings (P0-P3, defaults)\n  - Dependency creation with DepDiscoveredFrom\n  - Partial failure scenarios\n  - Edge cases (unknown types, empty values)\n\n**Test stats:**\n- 8 test functions\n- 21 test cases (using subtests)\n- Overall package coverage: 40.2%\n\n**What's NOT tested (requires API mocking):**\n- AssessIssueState() - Anthropic API call\n- AnalyzeExecutionResult() - Anthropic API call  \n- NewSupervisor() - Constructor\n- logAIUsage() - Simple logging wrapper\n\nThe core business logic is comprehensively tested. API integration tests would require complex mocking of anthropic.Client which is a separate effort (see vc-58, vc-59 for API improvements).\n\nAll tests pass: `go test ./internal/ai/... -v`","status":"closed","priority":0,"issue_type":"task","created_at":"2025-10-14T23:26:12.255136-07:00","updated_at":"2025-10-14T23:56:06.0133-07:00"}
{"id":"vc-61","title":"Fix variable shadowing in executor AI analysis loop","description":"In executor.go line 356, loop variable 'issue' shadows function parameter. This works but is confusing and could cause bugs during refactoring.","design":"Change line 356 in internal/executor/executor.go from:\n  for _, issue := range analysis.QualityIssues {\nto:\n  for _, qi := range analysis.QualityIssues {\n\tanalysisComment += fmt.Sprintf(\"- %s\\n\", qi)\n\nSimple one-line fix.","acceptance_criteria":"- No variable shadowing warnings\n- Code compiles and tests pass","status":"open","priority":2,"issue_type":"bug","created_at":"2025-10-14T23:26:12.255555-07:00","updated_at":"2025-10-14T23:56:06.013879-07:00"}
{"id":"vc-62","title":"Clarify or fix truncateString() behavior","description":"truncateString() in supervisor.go line 347 takes the LAST N characters, but the name suggests it should take the first N. For agent output we probably want the most recent (end), but the function is misleading.","design":"Two options:\n1. Rename to takeLastNChars() to be explicit\n2. Change implementation to s[:maxLen] if we want the beginning\n\nCurrent usage: truncateString(agentOutput, 2000) for AI analysis\nProbably want the END of agent output (most recent), so option 1 is better.\n\nAlso consider: taking both first 1000 and last 1000 chars to give AI context about what was attempted AND the final result.","acceptance_criteria":"- Function name matches behavior\n- Documentation clarifies head vs tail truncation","status":"open","priority":3,"issue_type":"task","created_at":"2025-10-14T23:26:12.256052-07:00","updated_at":"2025-10-14T23:56:06.014481-07:00"}
{"id":"vc-63","title":"Document or handle partial failure in CreateDiscoveredIssues","description":"CreateDiscoveredIssues() returns error after creating some issues (line 322). If 3 issues are created successfully and the 4th fails, the 3 already exist but we return an error. This could cause confusion or duplicates on retry.","design":"Options:\n1. Continue on error, collect all failures, return multi-error at end\n2. Implement transaction/rollback (delete already-created issues on failure)\n3. Document the behavior clearly and make retry idempotent\n4. Return (createdIDs, failedIssues, error) for partial success reporting\n\nOption 1 or 3 seems best for Zero Framework Cognition - let AI figure out what to do with partial failures.","acceptance_criteria":"- Behavior is documented\n- Retry logic handles partial failures gracefully\n- Logs clearly indicate which issues were created vs failed","status":"open","priority":2,"issue_type":"task","created_at":"2025-10-14T23:26:12.256411-07:00","updated_at":"2025-10-14T23:56:06.015025-07:00"}
{"id":"vc-64","title":"Optimize duplicate extractSummary calls in executor","description":"executor.go calls extractSummary(result) twice with same input (lines 309 and 340). Minor inefficiency - should reuse the variable.","design":"Move the extractSummary() call earlier (before AI analysis) and reuse:\n  // After agent completes (line ~304)\n  agentOutput := e.extractSummary(result)\n  \n  // Use in AI analysis (line ~309)\n  analysis, err = e.supervisor.AnalyzeExecutionResult(ctx, issue, agentOutput, result.Success)\n  \n  // Reuse for comment (line ~340)\n  if err := e.store.AddComment(ctx, issue.ID, e.instanceID, agentOutput); err != nil {","acceptance_criteria":"- extractSummary() called once per execution\n- Behavior unchanged\n- Tests still pass","status":"closed","priority":3,"issue_type":"chore","created_at":"2025-10-14T23:26:12.256741-07:00","updated_at":"2025-10-14T23:56:06.015399-07:00"}
{"id":"vc-65","title":"Replace fmt.Fprintf with structured logging (log/slog)","description":"Current code uses fmt.Fprintf(os.Stderr, ...) for warnings and errors. Should migrate to structured logging with log/slog for better observability and log parsing.","design":"1. Add log/slog setup in executor and AI supervisor packages\n2. Replace fmt.Fprintf calls with slog.Warn/Error with structured fields\n3. Add log levels configuration\n4. Use context-aware logging where applicable\nExample: slog.Warn('AI assessment failed', 'issue', issue.ID, 'error', err)","acceptance_criteria":"All fmt.Fprintf error/warning calls replaced with slog\nLogs include structured fields (issue IDs, error context)\nLog level is configurable","status":"open","priority":2,"issue_type":"task","created_at":"2025-10-14T23:26:12.257137-07:00","updated_at":"2025-10-14T23:56:06.015787-07:00"}
{"id":"vc-66","title":"Define magic numbers as constants","description":"Code has several magic numbers that should be named constants for maintainability. Examples: 2000 (truncate length in supervisor.go:267), 4096 (max tokens in supervisor.go), timeout durations, poll intervals.","design":"1. Create constants file or add to existing config\n2. Replace magic numbers with named constants:\n   - const maxAnalysisOutputLen = 2000\n   - const maxAITokens = 4096\n   - const defaultPollInterval = 5 * time.Second\n   - const defaultHeartbeatPeriod = 30 * time.Second\n3. Document why each value was chosen","acceptance_criteria":"No magic numbers in core logic\nAll constants documented\nTests still pass","status":"open","priority":3,"issue_type":"chore","created_at":"2025-10-14T23:26:12.257708-07:00","updated_at":"2025-10-14T23:56:06.016234-07:00"}
{"id":"vc-67","title":"Add performance metrics and tracing","description":"Add instrumentation for performance monitoring: execution times, AI API latency, issue throughput, success/failure rates. Important for production observability and identifying bottlenecks.","design":"1. Add metrics package (internal/metrics)\n2. Track key metrics:\n   - Issue execution duration (by type, priority)\n   - AI API call latency (assessment, analysis)\n   - Agent spawn/completion times\n   - Success/failure rates\n   - Issues claimed/completed per hour\n3. Expose metrics via:\n   - Prometheus endpoint (/metrics)\n   - Periodic log summaries\n   - In-memory stats accessible via CLI (vc stats)\n4. Add tracing for distributed debugging (optional: OpenTelemetry)","acceptance_criteria":"Key metrics tracked\nMetrics accessible via CLI and/or HTTP\nPerformance regressions detectable\nDocumentation for metrics interpretation","status":"open","priority":3,"issue_type":"task","created_at":"2025-10-14T23:26:12.258352-07:00","updated_at":"2025-10-14T23:56:06.016842-07:00"}
{"id":"vc-68","title":"Basic REPL loop with readline and command parsing","description":"Implement the core REPL loop with readline support, basic command parsing, and essential commands (exit, quit, help). Foundation for all other REPL features.","design":"Use github.com/chzyer/readline for full-featured input. Create internal/repl/repl.go with REPL struct and Run() method. Implement command routing to detect special commands vs natural language. Add graceful shutdown on exit/quit commands. Support command history in memory.","acceptance_criteria":"- vc repl command starts interactive shell\n- Readline with history support\n- exit and quit commands work\n- help command shows available commands\n- Ctrl+D exits gracefully\n- Colored prompt and output","status":"closed","priority":0,"issue_type":"task","created_at":"2025-10-14T23:26:12.258998-07:00","updated_at":"2025-10-14T23:56:06.017409-07:00","dependencies":[{"issue_id":"vc-68","depends_on_id":"vc-9","type":"parent-child","created_at":"2025-10-14T23:26:12.293558-07:00","created_by":"auto-import"}]}
{"id":"vc-69","title":"Status display commands (status, ready, blocked)","description":"Implement commands to show project state: ready work, blocked issues, in-progress work. Gives users visibility into tracker state.","design":"Add status.go in internal/repl/ with functions to display tracker state. Use storage.GetReadyWork() for ready command. Query blocked issues. Show in-progress issues. Use color-coded output for clarity. Include issue counts and priorities.","acceptance_criteria":"- status command shows overview (ready/blocked/in-progress counts)\n- ready command lists ready work with priorities\n- blocked command shows blocked issues and their blockers\n- Clean, color-coded output\n- Integration with storage layer","status":"closed","priority":0,"issue_type":"task","created_at":"2025-10-14T23:26:12.259585-07:00","updated_at":"2025-10-14T23:56:06.017835-07:00","dependencies":[{"issue_id":"vc-69","depends_on_id":"vc-9","type":"parent-child","created_at":"2025-10-14T23:26:12.293957-07:00","created_by":"auto-import"},{"issue_id":"vc-69","depends_on_id":"vc-68","type":"blocks","created_at":"2025-10-14T23:26:12.294522-07:00","created_by":"auto-import"}]}
{"id":"vc-7","title":"AI Supervision (Assess and Analyze)","description":"Add AI assessment before execution and AI analysis after execution. This is what makes vc intelligent - AI reviews every task and extracts hidden work. The 'secret sauce' that prevents agents from going off the rails.","design":"Integrate Anthropic Go SDK (Sonnet 4.5): 1) assessIssueState before execution (strategy, steps, risks, confidence), 2) analyzeExecutionResult after execution (completion status, punted items, discovered work, quality issues), 3) Auto-create discovered issues from AI analysis, 4) Log AI confidence and reasoning for debugging. Two AI calls per issue execution.","acceptance_criteria":"- Anthropic Go SDK integrated\n- assessIssueState activity implemented\n- analyzeExecutionResult activity implemented\n- AI confidence scores logged\n- AI reasoning/strategy logged to events\n- Auto-creation of discovered issues working\n- Integration with issue processor (Phase 2)\n- AI costs tracked and logged\n- Fallback handling for AI failures","status":"open","priority":0,"issue_type":"epic","created_at":"2025-10-14T23:26:12.259993-07:00","updated_at":"2025-10-14T23:56:06.018249-07:00","dependencies":[{"issue_id":"vc-7","depends_on_id":"vc-6","type":"blocks","created_at":"2025-10-14T23:26:12.295051-07:00","created_by":"auto-import"}]}
{"id":"vc-70","title":"AI conversation handler with agent spawning","description":"AI service that translates natural language input into structured issue definitions. Core feature enabling natural language interface.","design":"Create translator.go in internal/repl/. Use Anthropic API similar to AI Supervisor. Prompt engineering to extract: title, description, type (bug/feature/epic/task), priority. For complex requests, AI should create epic with child tasks. Handle edge cases (ambiguous input, clarification needed). Return structured issue data for creation.","acceptance_criteria":"- Translate simple requests to issues (e.g. 'Add login page')\n- Detect issue type from context (bug/feature/task/epic)\n- Infer reasonable priority\n- Handle complex requests by creating epics with subtasks\n- Error handling for unclear input\n- Integration tests with mock AI responses","notes":"Updated design: REPL should work like Claude Code. All non-slash-command input goes to Claude API which:\n1. Interprets user intent\n2. Can respond directly for questions\n3. Can create issues if needed\n4. Can spawn worker agents immediately to execute work\n5. Has function calling access to tracker operations\n\nThis is the VibeCoder Primitive - conversational interface with orchestration awareness.","status":"closed","priority":0,"issue_type":"task","created_at":"2025-10-14T23:26:12.260356-07:00","updated_at":"2025-10-14T23:56:06.018687-07:00","dependencies":[{"issue_id":"vc-70","depends_on_id":"vc-9","type":"parent-child","created_at":"2025-10-14T23:26:12.295547-07:00","created_by":"auto-import"},{"issue_id":"vc-70","depends_on_id":"vc-68","type":"blocks","created_at":"2025-10-14T23:26:12.295926-07:00","created_by":"auto-import"}]}
{"id":"vc-71","title":"Implement 'continue' command to resume execution","description":"The VibeCoder Primitive: 'let's continue' finds ready work and resumes execution. Can start executor or run single issue.","design":"Add continue.go in internal/repl/. Check for ready work. If none, inform user. If available, show options: 1) Run executor in background, 2) Execute single issue interactively, 3) Just show ready work. For single issue execution, show assessment, spawn agent, show real-time output. For background executor, show status updates.","acceptance_criteria":"- 'continue' command finds ready work\n- Shows user what's available\n- Option to execute single issue\n- Option to start background executor\n- Real-time status updates\n- Graceful handling when no work available","status":"open","priority":0,"issue_type":"task","created_at":"2025-10-14T23:26:12.26076-07:00","updated_at":"2025-10-14T23:56:06.019093-07:00","dependencies":[{"issue_id":"vc-71","depends_on_id":"vc-9","type":"parent-child","created_at":"2025-10-14T23:26:12.296346-07:00","created_by":"auto-import"},{"issue_id":"vc-71","depends_on_id":"vc-68","type":"blocks","created_at":"2025-10-14T23:26:12.296759-07:00","created_by":"auto-import"},{"issue_id":"vc-71","depends_on_id":"vc-69","type":"blocks","created_at":"2025-10-14T23:26:12.297239-07:00","created_by":"auto-import"}]}
{"id":"vc-72","title":"Polish REPL UX (tab completion, history persistence, Ctrl+C handling)","description":"Final polish: tab completion, persistent history, better error messages, Ctrl+C handling. Makes REPL production-ready.","design":"Add tab completion for commands using readline.PrefixCompleter. Persist history to ~/.vc/repl_history. Intercept Ctrl+C to not exit on first press (require exit command). Add better help text with examples. Improve color scheme for readability. Add welcome banner with quick start guide.","acceptance_criteria":"- Tab completion works for commands\n- Command history persists across sessions\n- Ctrl+C doesn't exit immediately\n- help shows useful examples\n- Welcome banner on startup\n- Clean, professional UX","status":"open","priority":1,"issue_type":"task","created_at":"2025-10-14T23:26:12.261443-07:00","updated_at":"2025-10-14T23:56:06.019702-07:00","dependencies":[{"issue_id":"vc-72","depends_on_id":"vc-9","type":"parent-child","created_at":"2025-10-14T23:26:12.297695-07:00","created_by":"auto-import"},{"issue_id":"vc-72","depends_on_id":"vc-68","type":"blocks","created_at":"2025-10-14T23:26:12.298124-07:00","created_by":"auto-import"},{"issue_id":"vc-72","depends_on_id":"vc-69","type":"blocks","created_at":"2025-10-14T23:26:12.298601-07:00","created_by":"auto-import"},{"issue_id":"vc-72","depends_on_id":"vc-70","type":"blocks","created_at":"2025-10-14T23:26:12.299062-07:00","created_by":"auto-import"},{"issue_id":"vc-72","depends_on_id":"vc-71","type":"blocks","created_at":"2025-10-14T23:26:12.299486-07:00","created_by":"auto-import"}]}
{"id":"vc-73","title":"Basic Dogfooding MVP - Make VC usable on another project","description":"Minimum viable VC to dogfood on a simple external project. The basic loop: user describes work → AI creates issues → /continue spawns worker → worker executes → results analyzed → follow-on issues created → repeat.","design":"**MVP Loop:**\n1. User in REPL: 'Add Docker support'\n2. AI creates epic + child issues\n3. User: '/continue'\n4. VC finds ready work, spawns Claude Code worker\n5. Worker executes, returns results\n6. AI analyzes, creates follow-on issues\n7. Repeat\n\n**Components needed:**\n- AI conversation → issue creation (function calling)\n- /continue command implementation\n- Worker spawning (Claude Code integration)\n- Results collection and storage\n- Basic activity feed (console output for now)\n- Simple test project (not VC itself)\n\n**Out of scope for MVP:**\n- Workflow automation (code → review → test)\n- Sandbox/worktree management\n- Swarming\n- Cost optimization\n- Full activity feed streaming\n\n**Success criteria:**\nCan fix a real bug or add a real feature to a simple external project using only VC REPL.","acceptance_criteria":"- AI in REPL creates issues from natural language\n- /continue command finds ready work\n- Worker spawns for single issue\n- Worker executes task completely\n- Results captured and stored\n- AI analyzes results and creates follow-ons if needed\n- Can complete a simple bug fix end-to-end\n- Can complete a simple feature addition end-to-end\n- Tested on external project (not VC)","status":"open","priority":0,"issue_type":"epic","created_at":"2025-10-14T23:26:12.262003-07:00","updated_at":"2025-10-14T23:56:06.020305-07:00"}
{"id":"vc-74","title":"Add function calling to AI conversation for issue creation","description":"Enable AI in REPL to create issues directly from conversation. Use Anthropic function calling to give the AI tools: create_issue, create_epic, add_dependency, get_ready_work, get_issue. When user says 'Add Docker support', AI should create appropriate issues automatically.","design":"Extend ConversationHandler to support function calling. Define tools:\n- create_issue(title, description, type, priority, design, acceptance)\n- create_epic(title, description) → returns ID\n- add_child_to_epic(epic_id, child_issue_id, blocks=true)\n- get_ready_work(limit=5)\n- get_issue(issue_id)\n\nUpdate system prompt to explain when to use each tool. AI should proactively create issues when user requests work.","acceptance_criteria":"- AI conversation supports function calling\n- Can create issues from natural language\n- Can create epics with children\n- Can query tracker state\n- Works in REPL: User: 'Add login page' → AI creates issue\n- Works in REPL: User: 'Build auth system' → AI creates epic + children","status":"closed","priority":0,"issue_type":"task","created_at":"2025-10-14T23:26:12.262372-07:00","updated_at":"2025-10-14T23:56:06.020705-07:00","dependencies":[{"issue_id":"vc-74","depends_on_id":"vc-73","type":"parent-child","created_at":"2025-10-14T23:26:12.299913-07:00","created_by":"auto-import"}]}
{"id":"vc-75","title":"Implement worker agent spawning from continue command","description":"The /continue command should find ready work and spawn a Claude Code worker to execute it. Single worker, single task for MVP. Collect stdout/stderr and exit code.","design":"Extend internal/executor/agent.go to support interactive spawning (not just from executor loop). Create spawnWorkerForIssue(ctx, issue) that:\n1. Prepares working directory\n2. Builds prompt with issue context\n3. Spawns Claude Code subprocess\n4. Streams output to console\n5. Waits for completion\n6. Returns result\n\nContinue command uses this to execute single issue interactively from REPL.","acceptance_criteria":"- /continue finds ready work\n- Shows user what will be executed\n- Spawns Claude Code worker\n- Shows worker output in real-time\n- Captures results\n- Updates issue status\n- Returns to REPL when done","status":"closed","priority":0,"issue_type":"task","created_at":"2025-10-14T23:26:12.262728-07:00","updated_at":"2025-10-15T00:25:34.025741-07:00","closed_at":"2025-10-15T00:25:34.025741-07:00","dependencies":[{"issue_id":"vc-75","depends_on_id":"vc-73","type":"parent-child","created_at":"2025-10-14T23:26:12.300293-07:00","created_by":"auto-import"},{"issue_id":"vc-75","depends_on_id":"vc-74","type":"blocks","created_at":"2025-10-14T23:26:12.300707-07:00","created_by":"auto-import"}]}
{"id":"vc-76","title":"Implement results collection and tracker updates","description":"After worker completes, collect results, run AI analysis, update issue status, create follow-on issues. Close loop from execution back to tracker.","design":"In continue command handler:\n1. Worker completes with AgentResult\n2. Extract output and exit code\n3. Call AI supervisor AnalyzeExecutionResult\n4. Parse discovered issues\n5. Create them with CreateDiscoveredIssues\n6. Update parent issue status (close if complete)\n7. Show summary to user\n\nReuse existing AI supervisor code from executor.","acceptance_criteria":"- Worker results captured\n- AI analysis runs automatically\n- Follow-on issues created if discovered\n- Parent issue closed if analysis says complete\n- User sees summary of what happened\n- Tracker state updated correctly","status":"closed","priority":0,"issue_type":"task","created_at":"2025-10-14T23:26:12.263132-07:00","updated_at":"2025-10-15T00:27:03.188131-07:00","closed_at":"2025-10-15T00:27:03.188131-07:00","dependencies":[{"issue_id":"vc-76","depends_on_id":"vc-73","type":"parent-child","created_at":"2025-10-14T23:26:12.301272-07:00","created_by":"auto-import"},{"issue_id":"vc-76","depends_on_id":"vc-75","type":"blocks","created_at":"2025-10-14T23:26:12.301738-07:00","created_by":"auto-import"}]}
{"id":"vc-77","title":"Add basic activity logging to REPL","description":"Show what's happening during execution. For MVP, just console output with timestamps. Full activity feed (vc-1) comes later.","design":"Add timestamped logging to REPL:\n- Issue claimed\n- Worker spawned\n- Worker output (streamed)\n- Worker completed\n- AI analysis started\n- AI analysis completed\n- Follow-on issues created\n- Issue closed\n\nUse color-coded output. Keep it simple - just fmt.Printf with colors.","acceptance_criteria":"- User sees what's happening\n- Timestamps on major events\n- Color-coded output\n- Worker output visible\n- Clear indication when done","status":"open","priority":1,"issue_type":"task","created_at":"2025-10-14T23:26:12.263516-07:00","updated_at":"2025-10-14T23:56:06.021851-07:00","dependencies":[{"issue_id":"vc-77","depends_on_id":"vc-73","type":"parent-child","created_at":"2025-10-14T23:26:12.302461-07:00","created_by":"auto-import"}]}
{"id":"vc-78","title":"Test MVP on external project (simple Go CLI)","description":"Create or choose a simple external Go CLI project. Test the full loop: describe work → issues created → /continue → execution → results → follow-ons. Validate end-to-end.","design":"Choose or create test project:\n- Option 1: Create simple todo CLI\n- Option 2: Use existing small open source Go project\n- Option 3: Simple HTTP server\n\nTest scenarios:\n1. Bug fix: 'Fix the error handling in parseArgs'\n2. Feature: 'Add --verbose flag'\n3. Multi-step: 'Add JSON output support'\n\nDocument what works and what doesn't. File issues for any problems.","acceptance_criteria":"- External project set up\n- Can describe work in REPL\n- Issues created automatically\n- /continue executes work\n- Results analyzed correctly\n- Follow-on issues created if needed\n- At least 2 complete bug fixes\n- At least 1 complete feature addition","status":"open","priority":1,"issue_type":"task","created_at":"2025-10-14T23:26:12.263883-07:00","updated_at":"2025-10-14T23:56:06.022304-07:00","dependencies":[{"issue_id":"vc-78","depends_on_id":"vc-73","type":"parent-child","created_at":"2025-10-14T23:26:12.302977-07:00","created_by":"auto-import"},{"issue_id":"vc-78","depends_on_id":"vc-74","type":"blocks","created_at":"2025-10-14T23:26:12.303514-07:00","created_by":"auto-import"},{"issue_id":"vc-78","depends_on_id":"vc-75","type":"blocks","created_at":"2025-10-14T23:26:12.304036-07:00","created_by":"auto-import"},{"issue_id":"vc-78","depends_on_id":"vc-76","type":"blocks","created_at":"2025-10-14T23:26:12.304526-07:00","created_by":"auto-import"},{"issue_id":"vc-78","depends_on_id":"vc-77","type":"blocks","created_at":"2025-10-14T23:26:12.305033-07:00","created_by":"auto-import"}]}
{"id":"vc-79","title":"Engineer-in-a-Box Workflow Automation","description":"Automatic workflow filing for the complete inner loop: code → review → test → gates → docs → git. Each worker that completes triggers the next phase automatically. This is Phase 2 after MVP.","design":"**Inner Loop Workflow:**\n\nFor each ready issue:\n1. Worker implements the code\n2. Haiku decides if code review needed (based on diff analysis, NOT heuristics)\n3. If needed: Review worker files granular issues for fixes\n4. High-priority fixes surface in queue via priority + dependencies\n5. Test checker reviews test sufficiency, files issues\n6. Quality gates run (lint, etc.) - worker can fix or defer\n7. Docs/cleanup\n8. Git operations (rebase, etc.)\n\n**Key principles:**\n- Zero Framework Cognition: AI makes decisions, not heuristics\n- Granular issues: Each fix is its own issue\n- No explicit 'implement review fixes' issue - dependencies handle it\n- Recursive review: Code review that touches significant code triggers another review\n\n**Out of scope (Phase 3+):**\n- Sandbox/worktree management\n- Mission planning\n- Swarming","acceptance_criteria":"- Worker completion triggers workflow automatically\n- Haiku-based review decision (not line count heuristic)\n- Review worker files granular fix issues\n- Test checker files test improvement issues\n- Quality gates auto-run\n- Recursive review triggers correctly\n- Full inner loop completes without human intervention\n- Can complete multi-step feature end-to-end","status":"open","priority":1,"issue_type":"epic","created_at":"2025-10-14T23:26:12.264226-07:00","updated_at":"2025-10-14T23:56:06.02287-07:00","dependencies":[{"issue_id":"vc-79","depends_on_id":"vc-73","type":"blocks","created_at":"2025-10-14T23:26:12.305531-07:00","created_by":"auto-import"}]}
{"id":"vc-8","title":"Quality Gates Enforcement","description":"Enforce quality standards before closing issues. All four gates must pass: go test, golangci-lint, go build. On failure, create blocking issues. Prevents broken code from being marked complete.","design":"After issue execution completes, run quality gate sequence: 1) go test (all tests must pass), 2) golangci-lint (zero lint errors), 3) go build (clean build). On any gate failure, create blocking issue with gate type label, mark original issue as blocked. Quality gates are mechanical - no AI decision making.","acceptance_criteria":"- go test gate implemented\n- golangci-lint gate implemented  \n- go build gate implemented\n- Blocking issue creation on failures\n- Gate failure details captured in blocking issues\n- Original issue status updated to blocked\n- Gate pass/fail logged to events\n- Integration with issue processor\n- Gate results visible in issue show command","status":"open","priority":0,"issue_type":"epic","created_at":"2025-10-14T23:26:12.266772-07:00","updated_at":"2025-10-14T23:56:06.023448-07:00","dependencies":[{"issue_id":"vc-8","depends_on_id":"vc-7","type":"blocks","created_at":"2025-10-14T23:26:12.305953-07:00","created_by":"auto-import"}]}
{"id":"vc-80","title":"Haiku-based code review trigger (ZFC principle)","description":"After any implementation, use Haiku to decide if code review is warranted. NO heuristics like line counts or file counts. AI understands semantic significance.","design":"**ZFC Violation to Fix:**\nOld way: 'If \u003e50 lines or \u003e10 files, trigger review' ← arbitrary heuristic\nNew way: Let Haiku decide based on actual diff analysis\n\n**Implementation:**\nAfter worker completes any issue:\n1. Get git diff of changes\n2. Send to Haiku (cheap, fast) with prompt:\n   'Analyze this diff. Does it warrant a code review?\n    Consider:\n    - Complexity and risk\n    - Critical paths touched (auth, security, data integrity)\n    - Test coverage\n    - Refactoring vs new features\n    - API changes\n    Return JSON: { needs_review: bool, reasoning: string }'\n3. If needs_review=true: File code review issue\n4. Log reasoning in comment\n\n**Cost:** ~$0.001 per check (Haiku)\n**Benefit:** Smart decisions vs arbitrary thresholds\n\n**Examples where heuristics fail:**\n- 10 line security change → SHOULD review\n- 200 line generated test boilerplate → probably NOT\n- 30 line auth refactor → SHOULD review\n- 100 line dependency update → maybe NOT\n\nHaiku understands context, heuristics don't.","acceptance_criteria":"- Haiku analyzes all completed work diffs\n- Decision based on semantic analysis not line counts\n- Reasoning logged for transparency\n- False positive rate \u003c 10% (unnecessary reviews)\n- False negative rate \u003c 5% (missed needed reviews)\n- Cost per decision \u003c $0.002\n- Integration with workflow automation","status":"open","priority":1,"issue_type":"task","created_at":"2025-10-14T23:26:12.26715-07:00","updated_at":"2025-10-14T23:56:06.023804-07:00","dependencies":[{"issue_id":"vc-80","depends_on_id":"vc-79","type":"parent-child","created_at":"2025-10-14T23:26:12.306363-07:00","created_by":"auto-import"}]}
{"id":"vc-81","title":"Add tests for conversation handler tool functions","description":"Add comprehensive tests for the AI conversation handler's tool execution functions. Cover valid inputs, invalid inputs, error handling, and integration with storage layer.","design":"Create internal/repl/conversation_test.go with tests for:\n- toolCreateIssue: valid/invalid types, missing fields, storage errors\n- toolCreateEpic: valid creation, error cases\n- toolAddChildToEpic: parent-child relationship, blocking relationships, both together\n- toolGetReadyWork: different limits, empty results\n- toolGetIssue: valid issue, missing issue\n- executeTool: dispatching to correct handler, error handling\n- Conversation loop: max iterations limit, tool use flow\n\nUse mock storage for unit tests. Add integration tests with real SQLite database.","acceptance_criteria":"- Tests for all tool handler functions\n- Valid and invalid input cases covered\n- Error handling tested\n- Mock storage used for unit tests\n- Integration tests with real database\n- All tests pass\n- Code coverage \u003e80% for conversation.go","status":"open","priority":2,"issue_type":"task","created_at":"2025-10-14T23:26:12.267552-07:00","updated_at":"2025-10-14T23:56:06.024215-07:00"}
{"id":"vc-82","title":"Add more conversation tools (update_issue, close_issue, add_dependency)","description":"Extend the AI conversation handler with additional tools for managing issues beyond creation. Allow AI to update issue status/priority, close issues, and add generic dependencies.","design":"Add new tool definitions in getTools():\n- update_issue(issue_id, status?, priority?, notes?): Update issue fields\n- close_issue(issue_id, reason?): Close an issue\n- add_dependency(from_id, to_id, type='blocks'): Generic dependency creation\n- list_issues(status?, type?, limit=10): List issues with filters\n\nImplement corresponding tool handler functions following the pattern of existing handlers. Use AIActor constant for all operations.","acceptance_criteria":"- update_issue tool implemented and working\n- close_issue tool implemented and working\n- add_dependency tool implemented and working\n- list_issues tool implemented and working\n- All tools use AIActor constant\n- Tools added to system prompt documentation\n- Manual testing shows AI can use all tools correctly","status":"open","priority":2,"issue_type":"task","created_at":"2025-10-14T23:26:12.267938-07:00","updated_at":"2025-10-14T23:56:06.024573-07:00"}
{"id":"vc-83","title":"Add rate limiting and safety controls to conversation tool use","description":"Prevent AI from creating unlimited issues or overwhelming the system during conversation. Add safety limits and user warnings.","design":"Add conversation-level tracking:\n- Track tool calls per conversation (reset on ClearHistory)\n- Max issues created per conversation (e.g., 20)\n- Max tool calls per message (e.g., 15)\n- Warn user if AI creates \u003e5 issues in single conversation\n\nConsider adding confirmation for bulk operations:\n- If AI tries to create \u003eN issues, ask user to confirm\n- Add /limits command to show current usage\n- Add ConversationStats struct to track metrics\n\nImplementation:\n- Add counters to ConversationHandler\n- Check limits in executeTool before running\n- Return error if limit exceeded\n- Log warnings for user visibility","acceptance_criteria":"- Max issues per conversation limit enforced\n- Max tool calls per message limit enforced\n- User warned when AI creates many issues\n- Limits are documented and tunable\n- Error messages explain what limit was hit\n- Manual testing shows limits work correctly","status":"open","priority":3,"issue_type":"task","created_at":"2025-10-14T23:26:12.268344-07:00","updated_at":"2025-10-14T23:56:06.024965-07:00"}
{"id":"vc-84","title":"Return structured JSON tool results instead of formatted strings","description":"Current tool handlers return formatted strings (e.g., 'Created task vc-82: Add feature'). Return structured JSON instead so AI can parse and reference results more reliably.","design":"Change tool handler return values from strings to JSON:\n\nBefore:\nreturn 'Created task vc-82: Add feature', nil\n\nAfter:\nresult := map[string]interface{}{\n    'status': 'success',\n    'action': 'created',\n    'issue_type': 'task',\n    'issue_id': 'vc-82',\n    'title': 'Add feature',\n}\nreturn json.Marshal(result)\n\nBenefits:\n- AI can extract issue IDs reliably\n- Easier to reference created issues in follow-up tools\n- More parseable for automated workflows\n- Still human-readable in conversation\n\nUpdate all tool handlers to return JSON. Keep error returns as strings (they're already structured by the SDK).","acceptance_criteria":"- All tool handlers return JSON objects\n- JSON includes action, status, and relevant IDs\n- Error handling unchanged (returns string errors)\n- AI can parse and use returned issue IDs\n- Manual testing shows AI correctly references created issues\n- Conversation readability not degraded","status":"open","priority":3,"issue_type":"task","created_at":"2025-10-14T23:26:12.268722-07:00","updated_at":"2025-10-14T23:56:06.025325-07:00"}
{"id":"vc-85","title":"Add godoc comments to conversation handler functions","description":"Add comprehensive godoc comments to all exported and internal functions in conversation.go. Follow Go documentation standards.","design":"Add documentation for:\n- getTools(): Explain tool definitions and function calling\n- executeTool(): Document dispatch pattern and error handling\n- All tool handler functions (toolCreateIssue, etc.): Document parameters, behavior, return format\n\nFollow godoc conventions:\n- Start with function name\n- Describe what it does\n- Document parameters and return values\n- Include examples where helpful\n\nExample:\n// toolCreateIssue creates a new issue from AI conversation.\n// Validates issue type and uses AIActor as creator.\n// Returns formatted success message with issue ID or error.\nfunc (c *ConversationHandler) toolCreateIssue(...) (string, error)","acceptance_criteria":"- All public functions documented\n- All tool handler functions documented\n- Comments follow godoc conventions\n- Comments are accurate and helpful\n- go doc output is readable","status":"open","priority":3,"issue_type":"chore","created_at":"2025-10-14T23:26:12.269072-07:00","updated_at":"2025-10-14T23:56:06.025716-07:00"}
{"id":"vc-86","title":"Improve get_issue tool output format","description":"The get_issue tool currently returns full JSON marshaled Issue struct, which is verbose and hard to read in conversation. Return a concise summary format instead.","design":"Change toolGetIssue from:\njson.MarshalIndent(issue, '', '  ')\n\nTo formatted summary:\nfmt.Sprintf(\"%s [%s] %s\\nStatus: %s | Priority: P%d\\nDescription: %s\\nDependencies: %d blockers, %d children\\nCreated: %s\",\n  issue.ID, issue.IssueType, issue.Title,\n  issue.Status, issue.Priority,\n  truncate(issue.Description, 200),\n  len(blockers), len(children),\n  issue.CreatedAt.Format('2006-01-02'))\n\nInclude only essential fields. Keep it readable in conversation context.","acceptance_criteria":"- get_issue returns concise summary format\n- Includes ID, type, title, status, priority, description (truncated)\n- Shows dependency counts (blockers, children, related)\n- Format is readable in AI conversation\n- Still includes enough detail for AI to work with","status":"open","priority":3,"issue_type":"task","created_at":"2025-10-14T23:26:12.269406-07:00","updated_at":"2025-10-14T23:56:06.026086-07:00"}
{"id":"vc-87","title":"Implement circuit breaker pattern for AI API calls","description":"Add circuit breaker pattern to prevent cascading failures when AI API is unhealthy. Circuit breaker tracks failure rates across requests and temporarily stops making calls when failure threshold is exceeded, giving the service time to recover.\n\nThis completes the resilience strategy from vc-59. Current implementation has timeout + retry, but no circuit breaker.\n\n**Problem:** Without circuit breaker, if AI API is down, every request will:\n- Wait 60s timeout\n- Retry 3 times with backoff (1s, 2s, 4s)\n- Total: ~3 minutes per request before giving up\n- All concurrent requests pile up, consuming resources\n\n**Solution:** Circuit breaker pattern with three states:\n- CLOSED: Normal operation, requests pass through\n- OPEN: Too many failures, block requests immediately (fail fast)\n- HALF_OPEN: Testing if service recovered, allow one request through\n\n**Reference:** Vibecoder used Temporal's built-in circuit breaker. We need lightweight Go implementation.","design":"In internal/ai/supervisor.go:\n\n1. Add CircuitBreaker struct:\n   - State: closed/open/half-open\n   - FailureCount, SuccessCount\n   - LastFailureTime\n   - Thresholds (configurable)\n\n2. Add to RetryConfig:\n   - CircuitBreakerEnabled bool\n   - FailureThreshold int (default: 5)\n   - SuccessThreshold int (default: 2)\n   - OpenTimeout time.Duration (default: 30s)\n\n3. Wrap retryWithBackoff with circuit breaker:\n   - Check state before attempting request\n   - If OPEN, fail immediately with ErrCircuitOpen\n   - If HALF_OPEN, allow single probe request\n   - Update state based on success/failure\n   - Thread-safe with mutex\n\n4. Add metrics logging:\n   - Circuit state transitions\n   - Failure/success counts\n\n**Implementation notes:**\n- Use sync.Mutex for thread safety\n- Log state transitions prominently\n- Make thresholds tunable via config\n- Consider adding metrics export","acceptance_criteria":"- Circuit breaker prevents cascading failures during API outages\n- OPEN state fails fast without retrying\n- HALF_OPEN state probes for recovery\n- State transitions logged with metrics\n- Configurable thresholds (failure/success counts, open timeout)\n- Thread-safe for concurrent requests\n- Tests cover all three states and transitions","status":"open","priority":2,"issue_type":"task","created_at":"2025-10-14T23:49:19.274913-07:00","updated_at":"2025-10-14T23:56:06.02662-07:00","dependencies":[{"issue_id":"vc-87","depends_on_id":"vc-59","type":"discovered-from","created_at":"2025-10-14T23:54:00.578209-07:00","created_by":"auto-import"}]}
{"id":"vc-88","title":"Epic completion logic uses wrong dependency direction","description":"The checkEpicCompletion() function in internal/executor/epic.go:24 uses GetDependencies() to find parent epics, but this is backwards. An epic DEPENDS ON its children, so we need GetDependents() to find which epics depend on the completed issue.\n\nLocation: internal/executor/epic.go line 24\n\nCurrent (incorrect):\ndeps, err := store.GetDependencies(ctx, childIssueID)\n\nShould be:\ndependents, err := store.GetDependents(ctx, childIssueID)\n\nResult: Epic auto-completion won't work because it's looking at the wrong side of the dependency relationship.","acceptance_criteria":"- checkEpicCompletion uses GetDependents() instead of GetDependencies()\n- Parent epics are correctly identified when child completes\n- Epic is only closed when all children are complete\n- Test verifies epic completion with multiple children","status":"open","priority":0,"issue_type":"bug","created_at":"2025-10-14T23:49:30.27538-07:00","updated_at":"2025-10-14T23:56:06.027305-07:00"}
{"id":"vc-89","title":"Quality gates error handling allows issues to close when gates didn't run","description":"In ResultsProcessor.ProcessAgentResult() at internal/executor/results.go:122-136, if gate runner creation fails, execution continues with GatesPassed=true. This allows issues to be marked complete even though gates never ran.\n\nLocation: internal/executor/results.go lines 122-136\n\nCurrent code:\nif err != nil {\n    fmt.Fprintf(os.Stderr, \"Warning: failed to create quality gate runner: %v (skipping gates)\\n\", err)\n} else {\n    gateResults, allPassed := gateRunner.RunAll(ctx)\n    result.GatesPassed = allPassed\n    ...\n}\n\nProblem: If gateRunner creation fails, result.GatesPassed remains true (default), allowing issue to complete without gates.\n\nFix: Set result.GatesPassed = false and block the issue when gate runner creation fails.","acceptance_criteria":"- Quality gate runner creation failure sets GatesPassed=false\n- Issue is marked as blocked when gates can't run\n- Error comment explains why gates failed\n- Test verifies behavior when gate runner creation fails","status":"open","priority":1,"issue_type":"bug","created_at":"2025-10-14T23:49:41.838714-07:00","updated_at":"2025-10-14T23:56:06.027883-07:00"}
{"id":"vc-9","title":"REPL Shell and Natural Language Interface","description":"Interactive shell for directing VC. Natural language interface that translates user requests into issues. The 'VibeCoder Primitive': user says 'let's continue' and system resumes from tracker state.","design":"Simple vc command with chat interface: 1) Accept natural language input from user, 2) Use AI to translate requests into issues (create epic, break into children), 3) Show activity feed of agent work, 4) 'let's continue' command resumes from current tracker state (finds ready work). The human\u003c-\u003eAI interaction layer.","acceptance_criteria":"- vc repl command starts interactive shell\n- Natural language input accepted\n- AI translation of requests to issues working\n- Issue/epic creation from natural language\n- Activity feed display in REPL\n- 'let's continue' command implemented\n- Tracker state visibility (what's ready, what's blocked)\n- Exit/quit commands\n- Command history\n- Integration with issue processor and AI supervision","status":"open","priority":0,"issue_type":"epic","created_at":"2025-10-14T23:26:12.269765-07:00","updated_at":"2025-10-14T23:56:06.028315-07:00","dependencies":[{"issue_id":"vc-9","depends_on_id":"vc-8","type":"blocks","created_at":"2025-10-14T23:26:12.306964-07:00","created_by":"auto-import"}]}
